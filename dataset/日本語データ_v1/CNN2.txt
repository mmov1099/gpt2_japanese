CNNとは、「Convolutional Neural Network」を略した言葉であり、日本語では「畳み込みニューラルネットワーク」とも呼ばれています。いくつもの深い層を持ったニューラルネットワークであり、主に画像認識の分野において価値を生んでいるネットワークです。
このCNNは、「畳み込み層」や「プーリング層」といったいくつかの個性的な機能を備えた層を積み上げることで構成されているのが特徴です。現在は、さまざまな分野で活用されていることから、その注目度も高まっています。
そんなCNNが主に価値を発揮しているのは、「一般物体認識」と呼ばれる画像認識のタスクです。この分野において、優れた性能を備えるアルゴリズムとして活用されています。
ただ、注目すべき点は圧倒的な性能を備えているという点だけではありません。たとえば、転移学習によってより効率的なネットワークの学習方法を確立することに成功したことなども、この技術が大きく注目されるようになった要因の一つと言えるでしょう。
CNNの仕組みを理解する上では、主に「畳み込み（convolution）」と「プーリング（pooling）」「全結合層（Affine）」という3つの層について把握する必要があります。
一般的なニューラルネットワークの場合、層状にニューロンを配置して、その前後の層に含まれたニューロン同士に関しては網羅的に結線していきます。しかし、CNNでは、ニューロン同士の結合をうまく制限するとともに、ウェイト共有という手法によって画像の畳み込みに近い処理を、ニューラルネットワークという枠組みの中で表現しているのです。
こういった役割の層を「畳み込み層」と呼んでおり、CNNにおいては特に重要な役割を担っています。
畳み込みと同様に重要な役割を担っているのが、プーリングと呼ばれる層です。CNNにおおける「畳み込み」の役割は、画像からのエッジ抽出等の特徴抽出でしたが、「プーリング層」に関してはその抽出された特徴が「平行移動などが起きても影響を受けることがないようにロバスト性を与える」という役割を担っています。
CNNは、主に画像をカテゴリごとに分類する作業（一般物体認識）において価値を発揮するネットワークとして知られています。ただ、写真に写った動物が犬なのか猫なのかを分類したい場合には、「犬と猫が正しく識別できる能力」を持たなければなりません。
そのため、写真の犬が左端に映っているか、右端に映っているか、といった情報は特に重要ではないわけです。つまり、画像のカテゴリを分けるタスクにおいて、あまり重要ではない「位置に関する情報」を上手に削ぎ落としているのが、この「プーリング層」なのです。
全結合層は、従来のニューラルネットワークにおける基本的な要素です。入力を2次元配列として扱うのではなく、単一のリストとしてすべてを同等に扱っていきます。すべての値は、現在の画像が×なのか○なのかという点で、それぞれに票を得ますが、このプロセスにおいては完全に民主的というわけではありません。
一部の値は、仮に画像が×だったときにそれを識別する能力が他よりも優れています。そしてその一方で、○の場合の画像を識別するのが非常に得意な値もあるのです。
これらの値は、他よりもたくさんの票を得ることがでいます。そして、投票の結果はそれぞれの値、もしくはカテゴリ間において、重みや連結強度などで表現されます。
新しい画像がCNNに示された場合、その画像が下位層を通過し、最終的に全結合層に達することになります。そして、選挙によって票数の多い答えが勝利し、入力のカテゴリを宣言するという流れになるわけです。
活性化関数とは、ニューロンから次のニューロンに出力を行う際、あらゆる入力値を別の数値に変換することで出力していく関数のことです。裁判長のような役割を果たす存在とも言えるでしょう。
出された証拠をすべて確認した上で、「本件は0.93対0.07で〇（マル）」というように判決するための確率計算式だとイメージすればよいでしょう。
2択の場合、あまりイメージが沸かないかもしれません。たとえば、100種類の花の名前などを当てる必要があるシーンなどでは重宝します。
私たち人間が物体を見るときに生じる経過としては、まず物体から反射された光が目の奥の網膜に像を結びます。そして、視神経を介して脳に刺激が与えられ、物体が何であるかを認識するという流れです。
このとき、物体の像全体を一度で把握するわけではありません。限定された領域ごとに、像をスキャンするように認識していくわけです。この限定された領域のことを「局所受容野」と呼びます。
局所受容野が受ける光の刺激は、電気信号に変換されて脳に達しします。そして、そこで視覚認識に関係するニューロンが反応するわけです。ちなみに、このニューロンには2つの種類が存在することが知られています。「単純型細胞」「複雑型細胞」と名づけられているものです。
畳み込み層は、局所的受容野だけでなく「重み共有」という工夫も行うことによって、パラメータ数の減少を実現します。重み共有は、画像が持つ「ある位置での重要な特徴に関しては、別の位置でも重要である可能性が高い」といった特徴を利用したものです。
たとえば、画像の中に犬がいるかどうかを学習するとしましょう。この場合、画像の中のさまざまな位置に犬が映っていることが想定されます。本来であれば、各位置にいる犬を別々のフィルタで学習しなくてはいけません。そのため、学習も困難になってしまうわけです。
しかし、犬がどこにいても同じように認識できるようになれば、その難易度は一気に下がります。「１つの畳み込み層の中では、１つのフィルタ（重み）を共有する」ということを実現するのが、重み共有の考え方なのです。
コンピュータに画像をピクセルごとに分割し、分割された数値の大きさにより画像の特徴を抽出しています。
普段僕らが目にしている鮮明な画像は、とても細かいピクセルで表現されているという訳です。
CNNが出てくるまでの問題点は、この画像認識における「特徴量の抽出」をいかに効率的に行えるか否かにあります。それを可能にしたのが、畳み込み層を含んだニューラルネットワーク構造、CNNになります。
とっての画像は、ある画像についてさまざまな角度でどんな物体なのかを読み取れる人間とは違い、単なる数値データで表現されます。
画像認識をより精度が高くなるように,言い換えると思い通りに画像を認識させたい時はどうしたらいいのでしょうか？
例えば、画像識別により猫を正解として判別させたいのに、余分な背景画像などを入力として受け取らせると情報量としてはかなり膨大となり、なおかつ精度に関しても、余分な画像も識別しようとしてしまうので低くなるのはなんとなく想像できます。
この課題を解決するのが、CNNという、「畳み込み層」を取り入れたニューラルネットワーク構造です。
畳み込み層の手順はフィルター（またはカーネル）と呼ばれる比較的サイズの小さい格子上の数値データと、同じサイズの部分画像（ウィンドウ）を用意
このフィルターとウィンドウを計算させることで、ある一つの値が求められるため、それを格納し、ストライドで設定した分だけフィルターをずらし、再度計算させる
全ての入力に対して計算が終了したとき、計算により得られた数値の集合が、局所的に抽出された特徴量として弾き出される
この数値をニューラルネットワーク上で計算させることで、どんな特徴を持った画像なのかを判別させる
畳み込み層をニューラルネットワークの入力層の前に置くことで、より特徴を持ちやすいデータを入力として受け取るということになります。
畳み込み層は識別したい画像の局所的に特徴量を抽出する層のこと。フィルターの大きさや数値ごとで特徴量に違いが出る。・フィルター（カーネル）
識別したい画像よりも比較的にサイズの小さい格子上の数値データ。フィルターにおけるサイズの大きさや数値データの値により、畳み込み層における特徴の抽出が異なる。・ウィンドウ
識別したい画像において、フィルターの大きさに合わせた部分画像の数値データ。フィルターと直接計算することになる。・ストライド
ウィンドウを動かす操作の度合いをストライドという。例えばストライドが「2」なら、一回の計算ごとに2つずつ、ずらすことになる。
畳み込み層と同様に、識別したい画像の特徴量を抽出する手法があります。それが「プーリング層」です。
この作業は、ウィンドウ自体の数値データから特徴量を抽出する手法となります。プーリング層に関しても図で解説しています。今回の図ではMAXプーリングを説明しています。
MAXプーリングでは、ウィンドウを均等に区切ることでグループ化し、その中で一番高い数値を特徴量として抽出します。MAXプーリング以外にも平均値プーリングなどもあります。
CNNではプーリング層は、畳み込み層とセットで用いられ、活性化関数での計算やバイアスを加えて訓練されます。
最後に、CNNを利用した画像認識技術の応用例を3つ紹介します。無人レジ店舗，ドライブレコーダーを活用した物体検出，医療における画像診断です．
ニューラルネットワークとは、人間の脳の神経回路を機械で再現する仕組みであり、神経と神経がつながるように情報を伝達していく仕組み。
実は私たちの脳は電気信号によって情報が伝達されているのですが、コンピュータには神経がありませんよね。ですから「コンピュータで人間の脳を再現した」のがニューラルネットワークと覚えておけば大丈夫です。
そして、ニューラルネットは入力層、中間層、出力層の三層に分かれています。入力層に入力されたデータが中間層を経由して出力層へ出力。そして、入力されたデータに重みをつけることで伝わりやすい情報と伝わりにくい情報を区別しています。
CNN(畳み込みニューラルネットワーク)とは、先ほどのニューラルネットワークの中間層に、さらに畳み込み層とプーリング層を組み込んだもの。
実はこれまでは計算量の莫大さから実現できていませんでした。しかしコンピュータの処理能力の向上で実現できるようになったのです。
CNNは、画像を複数のカテゴリに分類するように学習しており、この分野での能力は人間を上回ることもあります。CNNに新しい画像が渡された瞬間にその画像のどこにある特徴が含まれているのか。
例えば、その画像に猫が写っていた場合、あらゆる位置で猫の特徴と画像の特徴を比較し一致点と検出を試みます。この作業を畳み込みといい、それぞれの特徴で行われた畳み込みが画像セットとして出来上がります。
これを畳み込み層と言います。確かにこれまでのコンピュータでは処理できないことが理解できますよね。
次に画像を集約するのがプーリング層です。
先ほど抽出したデータをプーリング（圧縮）します。その結果、4分の1程度に圧縮。ここで圧縮することで処理が簡単になります。
ここまでの一連の流れがCNNの内部構造です。
CNNとは第一に画像認識をするために作られたものです。しかし、CNN以外にも画像認識をする手法はいくつかあるのですが、画像認識やディープラーニングにCNNが用いられるには理由があります。
これまでの普通のニューラルネットワークでは、入力に単一ベクトルを受け取り、それを一連の隠れ層を通して出力されます。畳み込み層やプーリング層がありません。一応一般的なニューラルネットワークでも画像データを取り扱うことは可能です。しかし、複雑な画像に関してはほとんど正確さを持たないことが多いです。
対してCNNは、畳み込み層で画像セットを作り出しプーリング層で圧縮することで高度な計算を可能としています。そしてCNNは画像内の空間的・時間的な依存関係を正常に取得することができるのです。
これらの理由から画像認識やディープラーニングにCNNが使用されるのが主流になっています。
このように万能そうに見えるCNNですが、注意すべき弱点が存在します。
それは、人間の目にはわからないようなちょっとしたノイズを写真に追加した場合、全く別物として認識してしまうこと。
でも画像を認識するだけなら、ノイズを入れなければ良いと考えますよね。
画像認識をするだけなら大きな問題にはなりませんが、自動運転技術にCNNを応用した場合のことを考えてみてください。もし、ハッカーがノイズを送り続けた場合どうなるでしょうか。自動走行車が判断を誤って事故を起こす可能性だって大いにあります。
もうひとつの欠点に、プーリング層で圧縮する際に、位置に関する情報をそぎ落としてしまうため、従来のCNNでは、目の上に口が存在していても「人の顔」として認識されてしまうということ。
CNNとは畳み込みニューラルネットワーク（CNN）は、画像からパターンや物体を認識するために最もよく利用されるニューラルネットワークの一つです。
畳み込み層においてフィルタ処理を行うこと(後述します)が大きな特徴として挙げられます。
ここからは、CNNの仕組みについて解説してきます。CNNがなぜ画像認識で高い精度を上げられたかというと、模様や、犬の顔などのより複雑な特徴を学習できるようになったからです。
具体的には、CNN以前は画像を1次元のベクトルとして学習させていたものが、2次元の行列で学習できるようになりました。
CNNが出てくる前の全結合型のニューラルネットワークなどを使った画像認識では、1次元の数字の羅列として学習します。
しかし、2次元の画像のデータでは、あるピクセルとその周りにあるピクセルの関係は、画像の特徴を知る上でとても重要な情報です。1次元のデータとして学習させた場合は、このようなあるピクセルとその周辺のピクセルのような情報は抜け落ちてしまうのです。
そのため、CNNが出てくる前の画像認識は画像の特徴をうまく学習することができずに、精度向上が頭打ちになってしまっていました。画像データをそのまま2次元データとして捉えることができるCNNは、革新的なネットワークだったと言えます。
例えば、MNISTの場合は、白黒の画像を集めたデータセットで背景を黒、数字を白として表現しています。そのため、どこかのピクセルが白であれば、そのピクセルに隣接するピクセルは白である可能性が高くなります（白いピクセルが1個だけ点在しているというケースは数字の場合はないと言って良いでしょう）。
ただし、数字と背景の境界辺りでは、周りに黒いピクセルもあるでしょうし、実際にはそのような白いピクセルと黒いピクセルとの関係が数字の「特徴」を表すことになります。このように、画像には2次元のデータとして学習することで認識できる特徴がいくつもあるのです。
CNN以前の全結合型ニューラルネットワークを活用した学習の場合、1次元のデータとして学習するので、このような2次元データ特有の特徴を無視することになってしまいます。これらの情報を加味するために活用されているのがCNNです。
CNNでは2次元のデータを小さな区分に分割して、それらと何らかの特徴を表すデータとを比較しながら、元のデータがどんな特徴を含んだものであるかを調べていきます。
何らかの特徴を表すデータのことを「カーネル」と呼ぶことにします。他にはフィルタと言う呼び方をしたりもします。文脈によって違う言葉が使われていたりするので注意しましょう。
カーネルとはこのような特徴を表すもので、画像データ（を分割した小さな部分）にどんな特徴が含まれているかを調べるために使われます。
実際には、Lの特徴で記述したようなものを人間が書く必要はありません。CNNを使うと、ある画像がどんな特徴を持っているかニューラルネットワークが学習してくれいます。
その具体的な過程として、プーリングや活性化関数などの処理を経て、全結合を行うネットワークに接続され、その画像が何であるかの推定を行います。
カーネルは、3×3などの小さな2次元データだと考えてください。ここでは3×3のサイズの2次元配列とし、これと先ほどのLのデータを例として、どんなことが行われるかを紹介します。
この場合の、カーネルの値は学習により得られたものだとします。まず、画像データにカーネルを適用するときの手順は次のようになります。
左上から右下に向かって、カーネルのサイズと同じサイズのデータを取り出す。
カーネルを使って行列の演算を行っていく。
その結果をCNNからの出力に左上から並べていく。
このように、元の画像データの区画とカーネルとの行列演算を行った結果を出力としていく処理が「畳み込み」です。この出力を「特徴マップ」と呼ぶこともあります。
また、上の例の場合、畳み込みにより、出力データのサイズが元の画像データよりも小さくなっています。入力画像は5×5だったにも関わらず、出力画像は3×3になっています。
このようなデータサイズの減少を避けたり、画像データの端にあるデータを使った畳み込み処理の回数を増やしたりするなどの目的で画像データの上下左右に「パディング」と呼ばれる要素（値は一般に「0」のことが多い）を付加することもあります。
例えば、先ほどのLを表現した5×5の2次元データの周りに0という数字を加えて（パディング）、7×7の2次元データにしてから、3×3のカーネルで畳み込み演算をしたとすると、出力データは5×5になります。このように、元の画像データの外周にピクセルを加えることで、出力データのサイズが変わらないように処理することが可能です。
そして、CNNではプーリングという重要な処理があります。「プーリング」とは畳み込みによって得た特徴（特徴マップ）から重要な要素は残しながら、データ量を削減する処理です。
入力（特徴マップ）を小さなサイズの区画（2×2、3×3など。これも「ウィンドウ」や「カーネル」と呼びます）に分けて、その区画内で特徴的な値（最大値、平均値など）を取り出して、それをプーリングの出力とします。
元の特徴マップは3×3だったので、そこからプーリング処理を行うことで、2×2の区画から最大値2を抽出することができました。元々の特徴マップのデータ量からデータを削減することに成功しました。
ちなみに、プーリングには畳み込みと同様の特徴があります。それは、入力（この場合は特徴マップ）の中で多少のズレがあっても、もともとの特徴を示すデータをうまく拾い上げられる点です。
画像データはピクセル単位での処理をするので、元のデータや重み、バイアスなどによって、特徴マップのどこに特徴といえる値が出てくるかはそのときどきで変わるかもしれません。
そんなときでも、プーリングを行うことで必要なデータをうまく取り出せるのがプーリングのメリットと言えます。
全結合層では畳み込みとプーリングを行った後に特徴部分が取り出された画像データを一つのノードに結合し、活性化関数（後述）によって変換された値（特徴変数）を出力するものです。CNNでは、入力画像とそれに対応する正解データが学習データとして与えられます。
そして、畳み込みフィルタやプーリングによる重みなどを最適化することによって学習が行われます。このパラメータの最適化を効率的に行うテクニックとして、代表的なものに活性化関数を使う手法があります。具体的にはフィルター適用後の画像データに活性化関数（ReLU: Rectified Linear Unit）を適用するという手法です。
活性化関数（ReLU）とは、0未満の出力値をすべて0にする関数で、ある閾値以上の部分だけを意味のある情報として次の層に送る働きをします。畳み込みフィルターや全結合層の後に置かれ、抽出された特徴をより強調する働きがあります。
畳み込みとプーリングとその間のReLUなどの活性化関数という組み合わせを何層かに重ねることで、入力層に近いところでは今述べた微細な特徴を表現し、入力層から遠い層では全体的な特徴を表現できるようになります。
その過程で得られたものを全結合により推測を行う層（全結合層）へと渡して、最終的に分類を行うというのがCNNによる画像認識の手順になります。
CNNの処理の全体像
図6：CNNの処理の全体像
CNNでできることは大きく分けて2つあります。それぞれについて解説していきましょう。
画像認識
画像生成
CNNでは画像生成もできます。
例えば、白黒写真の色付け鳥や犬などの画像の作成などができます。なぜCNNで画像生成ができるかというと、CNNを活用することでより複雑な特徴を学習できるからです。
具体的には、CNNは画像の線や色合いといった簡単な特徴だけではなく、画像の模様のようなやや複雑な特徴や、犬の顔や鳥の足というような複雑な特徴まで学習することが可能です。
低レベル特徴〜高レベル特徴の例
低レベル特徴：線や色
中レベル特徴：模様
高レベル特徴：犬の顔、鳥の足
その他にも、次のようなタスクが可能です。
ラフスケッチの自動線画化：ラフスケッチに対して線を描き足してきれいな線画にするタスク
画風転写：画家の画風を他の画像に反映させるタスク
物体検出：画像の中から特定の物体を検出するタスク
セグメンテーション：画像の中から特定の物体を切り出すタスク
まとめるとCNNは画像を使うタスクであれば、応用範囲はかなり広い技術であると言えます。
今回は、主に画像認識や画像生成のタスクで活用されているCNNについて解説しました。簡単に言えば、畳み込み演算とプーリング＋活性化関数を活用した特徴の強調を繰り返すことで、画像の部分的な特徴と全体的な特徴を学習していき、画像の特徴量の学習を最適化していくネットワークです。
このように、画像を2次元データとして捉えて、特徴を学習する手法が用いられ始めたことで画像認識の精度は向上し、応用の範囲も格段に広がりました。
具体的には下記のような用途に活用できます。
画像認識（例：犬の顔などを見分けるなど）
画像生成（例：白黒画像からカラー画像へ変換するなど）
画風の再現（例：持っている写真をモネ風のタッチに変換するなど）
物体検出（例：道路の写真から車だけ抽出するなど）
セグメンテーション（例：草原の画像の中からシマウマの輪郭だけを切り取るなど）
デッサンの線を描く（例：鉛筆の軽いタッチのでデッサンの線を太くするなど）
畳み込みニューラルネットワーク（たたみこみニューラルネットワーク、英: Convolutional neural network、略称: CNNまたはConvNet）は層間を共通重みの局所結合で繋いだニューラルネットワークの総称・クラスである。機械学習、特に画像や動画認識に広く使われる。
CNNは、その重み（行列の）共有構造と並進不変特性に基づいて、シフト不変（shift invariant）あるいは位置不変（space invariant）人工ニューラルネットワーク（SIANN）とも呼ばれている。








