Attentionとは
入力側のどこに注目するかを表現する仕組み、あるいは注目した入力データに従って出力を行う仕組み
複数のベクトル (行列) があったとき、どのベクトルを重要視するかも含めて学習させる仕組み.


Attentionの基本的な処理
Query と Key をスコア関数に入力して重要度スコアを計算
Softmax 関数で割合化・確率化し重要度確率を計算
Value と重要度確率で、重み付き平均の計算を実施し、Value から有益な情報(コンテキストベクトル)を取得


Attention の目的
Attentionは、Query と Key が似ているかどうかで、行列のどの要素(ベクトル)を読み込むかどうかを制御している. 画像データの位置関係 (空間的に近いデータ点同士の方が強い関係性を持つ)や、時系列データの系列関係 (時系列的に近いデータ同士の方が強い関連性を持つ)を 度外視して(空間的、時系列的に遠い情報でも重要かどうかを見ているため)、重要な情報同士をまとめることができる.


Attentionの構造
Attentionのキーワードは「Query」「Key」「Value」です。
Query : 「これに関係するものは何か」を知りたい要素です。
上記の例で言えば「簡単」の1つ前の「は」のhidden stateがqueryです。
Key : 「これらの中のどれに注意を向ければよいか」を知りたい要素です。
上記の例で言えばEncoderの全てのhidden stateです。
Value : 多くの場合Keyと同じ要素です。queryとkeyから計算した重みを掛けるために使われます。


Attentionの計算は次のような手順で行われます。
queryとkeyのエネルギーe(類似度、重要さ)をCompatibility functionで計算します。
eをDistribution functionで正規化し、Attention weights aを計算します。
aとValueの各要素の積を取り、context vectorを計算します。


Attentionは最近流行っている仕組みです。
Attentionは、CNNと組み合わせて使われます。
CNNと組み合わせることで、比較的簡単な構造で性能を向上させることができる。
Attentionはニューラルネットワークの広い分野で利用されている。


Attentionの概要について説明する。
まず第一段階として、CNNを用いて多くの入力データから簡単な特徴を抽出する。
第2ステップでは、入力から生成された特徴量を全て使うわけではありません。そこで、ネットワークはそのうちのいくつかに着目する。
そして、フォーカスされた特徴はニューラルネットワークの推論に使われる。
データの一部、つまり特徴に焦点を当てるので、Attentionと呼ばれる。
Attentionは自然言語処理の分野で発展してきた仕組みである。


簡単な例として、画像処理を紹介。
CNNを用いた画像認識について考えてみよう。
寿司の画像を例にとって考えてみよう。
寿司画像は物体認識の問題として考える。
これはブリ（鰤）の画像である。
人間は画像のブリの部分だけを見れば、その物体がブリかどうかを判断できる。
通常のCNNの場合、画像全体が入力としてネットワークに与えられます。
そのため、画像認識は背景の領域に非常に敏感です。
この画像は、黒いお皿の上に「ぶり」が乗っています。
お皿の色が変わっても、お皿の上のお寿司は同じです。
お皿の色がどうであれ、「ぶり」という答えを期待するのです。
ネットワークには背景のある画像が与えられるので、出力は背景の影響を受ける。
この影響を軽減するために、人間の注意力であるフォーカス機構を画像処理に導入しています。
ここでは、画像の寿司だけに注目する方法を考える。
これが画像処理分野における「Attention」の概念である。


まず、入力画像から簡単な特徴量を抽出する。
次に、関心領域を推定するニューラルネットワークに分岐する。
このマスク画像のように、CNNから関心領域を推定するマスクを取得する。
この注目領域の画像で入力画像をマスクする。
すると、左下の画像のように、寿司の部分のみを抽出することができる。
このように、寿司の部分だけを抽出することで、後段で背景を無視した物体認識を構築することができる。
以上が画像認識分野におけるアテンションの一例である。
画像処理におけるAttentionは、もっとわかりやすい。
Attentionとは、関心領域を推定する仕組みである。
これは簡単な例であった。


通常のCNNで考えてみよう。
CNNの最初のステージで作成された特徴マップにアテンションを適用する。
この概念をSqueeze-and-Excitation Network (SENet)という。
SENet はマスク情報を構築し、各特徴量マップの関心領域を推定する。
この例では、1つ目の特徴マップと3つ目の特徴マップが認識上重要である。
そこで、1番目と3番目のマップに対してマスクを構築し、注目する特徴を推定する。
構築したマスクを元の入力画像に適用することで、このような特徴マップ群を得ることができる。
これらの特徴マップは、後段のニューラルネットワークに使用される。
以上で画像処理のAttentionの説明は終わりです。



Attentionが元々開発された自然言語処理の分野
これは文章を分類するネットワークでのAttentionの例である。
例として、入力文が肯定的な感情か否定的な感情かを判断する文の分類の問題を考えてみる。
入力文を単語に区切り、各単語の特徴量を出力する。
すると、一般にCNNやRNNは、正負のラベル情報を直接推定する。
Attention機構を導入することで、判断に有用な単語の特徴のみを抽出することが可能である
を抽出し、その特徴量に基づいて推定を行うことができる。
この例では、「おいしい」という単語が有用である。
この単語は、肯定的か否定的かの判断に大きな影響を与える。
したがって、この単語だけに注目し、他の単語は出力にほとんど影響を与えない。
このように、Attentionは文の分類に応用することができる。


Attentionの翻訳の例について
これはAttentionを用いずにLSTMを用いて翻訳を行った例である。
どのように翻訳が行われるかを説明する。
前の例と同様に、文を単語に区切り、各単語に対してLSTMを用いて特徴量を生成する。
特徴量の生成にはエンコーダを用いる。
これはLSTMの時間発展型モデル（Sequence to Sequence）に基づいている。
このモデルは全ての単語に対して特徴を抽出する。
次に、このモデルは原文全体の特徴から翻訳後のテキストを生成する。
デコーダはそのテキストを文頭から単語単位で翻訳していく。
Attentionなしの翻訳はこのような仕組みになっている。
人間がこの文章を翻訳するとき、最初から文章全体を見ているわけではありません。

Attentionを使った翻訳について説明します。
私たち人間は、この文章を翻訳するとき、最初から文章全体を見ているわけではありません。
例えば、文中の主語をまず探します。
例えば、「ぶり」という単語に注目してみましょう。
この場合、「ぶり」という特徴を利用して訳語を作ります。
アテンションは、人間が翻訳するのと同じようなことができる。
これは、前の画像の例と同様です。
まず、各単語の特徴を抽出する。
そして、先ほどのデコーダーの出力とエンコーダーの出力を掛け合わせ、ソフトマックスを適用する。
そうすることで、どの単語に注目するかを決めることができる。
この例では、2番目の単語である「ぶり」に着目することが決定される。
そして、「ぶり」という特徴量をもとに、出力する単語を決定している。
各ステップで注目する単語を決定するために、Attentionが使われる。
このようなプロセスを経て、Attentionを使った翻訳後の文章ができあがる。


Attentionを使って翻訳の精度を上げる例
精度を上げるために、Query-Key-Valueを用いたSource-Target Attentionが提案された。
このモデルでは、エンコーダが検索用にKeyという素性を出力し、実際の翻訳用にValueという素性を出力する。
つまり、Encoderの出力を分離するためのモデルである。
先ほどの例と同様に、Decoderも素性を持つ。
このモデルでは、Decoderの素性はQueryと呼ばれる。
前の例と同様に、Decoderの最初の単語を決定してみよう。
最初の単語はQueryとして与えられる。
そして、最初の単語に対するすべてのキーの応答をチェックする。
Keyのレスポンスが最も大きい単語のValueを使ってFeatureを作成する。
作成した特徴量を元に、次の単語の翻訳単語を決定する。
では、その手順を順番に見ていこう。
まず、対象のQueryに全単語のKeyを掛け合わせる。
乗算結果が最も高い単語に注目する。
これにより、注目する領域の特徴量の効果が高まり、他の領域の特徴量の効果が減少する。
そして、この注目によって得られた特徴量を用いて、翻訳された単語を作成する。
これがソース・ターゲット注目の仕組みである。


Self-Attention
先に説明したソース・ターゲット注目の場合、Key / ValueとQueryは異なるソースから生成される。
翻訳の例では、Key / ValueはEncodeから、QueryはDecoderから生成される。
Self-Attentionの場合、Key/ValueとQueryは同じソースから生成される。
そこで、Self-Attentionは、自ら生成したKey/Queryを用いて、自ら生成したValueに重み付けを行い、合計する。
文中のSelf-Attentionの例をこの図に示す。
Self-Attentionは、Encoder側で特徴量間の関係を考慮することができる。
「このブリはおいしい」という文では、"おいしい "という単語が "ブリ "を特徴づけている。
「このブリはまずい」という文の場合、"不味い "という単語が "ブリ "を特徴付けている。
"おいしい "や "不味い "という単語は、前の単語 "ブリ "を特徴付けると考えられる。
つまり、入力データの単語間の関係性を考慮することができる。
Self-Attentionのポイントは、入力データ中の関係性に着目できることである。


Self-Attentionの例
まず、Queryと処理対象の単語のすべてのKeyの内積を取る。
ここでは、「ブリ」に着目し、Queryの周辺にある他のKeyを参照する。
最も関連性の高い単語である「delicious」に着目する。
そして、各単語からValueを受け取る。
Valueを受け取ると、重みが高いほど反映されるように重み付けを行う。
そして、最終的な特徴量を作成する。
Attention後の情報は、入力された単語と重み付けされたValueの和となる。
以上のように、Self-Attentionは文中の単語間の関係性を抽出することができる。


自然言語処理の分野でのSelf-Attentionの例
Self-Attentionは、画像処理にも応用できる。ニューラルネットワークによって抽出された特徴マップの集合から、各Query Key Valueを生成する。
自然言語の場合と同様に、QueryとKeyから重要な部分を見つける。
そして、その値を重み付けして合計する。
そして、重み付け和から得られた特徴を、元データの特徴に追加する。
このように、重要な特徴に着目することで、Attentionを画像処理に応用することができる。


Self-Attentionを画像に利用するメリット
まず、離れた場所にある特徴量を考慮することができる。
"画像に写っているブリはおいしいか？"という分類問題を解くニューラルネットワークを考えてみましょう。
左の入力画像ではブリが小さく、通常のCNNでは分類が困難です。
しかし、空間的に離れた場所にある「華麗な笑顔」という情報を使って分類することができれば、「ブリ」を「美味しい」と感じることができる。
もし、笑顔の素敵な男性が写っていなかったら、"ブリ "が美味しいかどうか判断できないかもしれません。
仮にいたとしても、「笑顔の素敵な男性」と「ぶり」は、通常のCNNでは遠すぎるため、この問題を解決することは難しい。
しかし、Self-Attentionの仕組みを応用すれば、空間的に離れた画像特徴量を組み合わせることができる。
それらを組み合わせることで、「ブリが美味しい」と推論できるかもしれない。
現在では、自然言語処理や画像処理など、さまざまな応用分野を持つAttentionを見られる。




