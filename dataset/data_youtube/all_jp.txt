まず、ニューロンモデルを見てみましょう。
これはニューラルネットワークの基礎となるものです。
ニューロンモデルには大きく分けていくつかあります。
まず、スパイクニューロン・モデルです。
これは、脳の神経細胞を模したものです。
このように、スパイクの回数やタイミングなどで情報をコーディングします。
このニューロンモデルは、どちらかというと生物の脳に近いと思います。
次に、この人工ニューロンモデルです。
これは脳の機能を抽象化したようなもので
で、ニューロンの発火頻度を実数で表現したものです。
ニューラルネットワークには、大きく分けてスパイク型ニューラルネットワークと人工ニューラルネットワークの2種類があります。
スパイクニューラルネットワークは、生物の脳を目指したアプローチのニューラルネットワークです。
人工ニューラルネットワークモデルは、工学的に有用なものを目指したアプローチです。
今回は、人工ニューロンモデルの基本を紹介する。
この図は、人工神経細胞モデルを表したものです。
図中の円は神経細胞を表しています。
矢印はシナプスを表す。
シナプスは結合の重み付けであるWを持つ。
シナプスは結合重み付け W を持ち、結合重み付け W と入力の乗算にバイアスをかける。
非線形関数を適用し、その値を出力する。
この後、この図の丸と矢印がよく出てくる。
この矢印のところに重みWが設定され、入力との乗算積算演算がとられる。
式で書くとこんな感じになります。
このような図を見たら、掛け算の演算式をモデル化したものと思ってください。
このニューロンモデルの数学的意味を、簡単な例で理解してみましょう。
このような一次式が何を意味するのか考えてみましょう。
入力Xが2次元のベクトルだとすると、この式はこの図のようになります。
2次元ですから、直線式になります。
この直線で何ができるかというと、この空間を上か下かのように区切る直線を引くことができるのです。
ここで、n次元の空間を考えてみよう。
例えば、3次元ではこのようになります。
これを拡張したn次元でも同じことが言える。
超平面が多次元空間を区切っている。
これが、1つのニューロンを持っているときの数値的な意味です。
次に、ニューラルネットワークの話をしたいと思います。
先ほど紹介したように、1つのニューロンでできることは
n次元の空間をn-1次元の超平面で分離することです。
このような分離で解ける問題を線形問題と呼びます。
つまり、ニューロンモデルを使えば、線形問題を解くことができるのです。
左はANDの例、右はORの例です。
AND論理では、両方の入力が1であれば出力は1、一方または両方の入力が0であれば出力は0になります。
このANDを線形問題として解くには、ここに直線を引き、その直線が
が分離面より大きいか小さいかを判断する。
そうすることで、ANDはニューロンモデルで解くことができます。
また、右の例のORも同様です。
ORの場合は、ここに線を引くことで解くことができます。
ここで質問ですが、XORの問題を1本の直線で解くことができるでしょうか？
答えはNOです。
分離するための線を引いてみてください。
ここに線を引くと、上側は分離されますが、下側は1と0が混在しています。
一本の直線で分離されるわけではありません。
また、このように線を引いても分離することはできません。
このXOR問題は、直線的に分離できない典型的な問題です。
非線形問題とは、直線平面上では切り離せない問題のことです。
非線形問題と呼ばれる。
これを何とかして解きたい。
非線形問題を解くために、隠れ層を持つニューラルネットワークを導入してみよう。
線形問題は1つのニューロンで解くことができた。
このようなネットワークを構築することにする。
この場合、隠れ層に2つのニューロン、出力層に1つのニューロンを用意します。
入力を隠れ層で線形に区切られた空間に変換し、隠れ層で区切るというものです。
しかし、いくら線形モデルを積み重ねても、結局は線形モデルになってしまう。
この隠れ層で、活性化関数と呼ばれる非線形関数を適用するのです。
このような構成のニューラルネットワークをMLP（Multi-Layer Perceptron）と呼びます。
MLP は、ニューラルネットワークの最も基本的な構造です。
ここに示すように、いくら線形モデルを積み重ねても
1つの線形行列として終わってしまいます。
これを防ぐために活性化関数を適用しています。
この例では、活性化関数としてReLUという非線形関数を用意しました。
ReLUの構造はこの図の通りである。
入力が負の場合は0を返し、正の場合は入力をそのまま出力に返す。
このような構造を持つ非線形関数である。
このとき、Wを表す矢印をすべて1にし、バイアスを0と-1にする。
そして隠れ層空間を作る。
入力空間では、どう直線を引いても分離することはできませんでした。
しかし、この空間を変形して隠れ層空間に持っていくと
H1 と H2 の空間に直線的な分離を見出すことができます。
ここに直線を引くことで0と1を分離することができるのです。
このようにニューラルネットワークを作ることで、1つの線形ニューロンでは解けなかったXOR問題を把握することができる。
XOR問題を多層パーセプトロンの隠れ層空間における線形分離問題として解くことができるのです。
以上が非線形問題の基本的な考え方である。
そして、これから様々なニューラルネットワークを構築していく。
入力層と出力層の構造は、問題が決まれば決めることができる。
先ほどのXORの例では、入力がX1とX2の2次元なので、入力層の数は2つです。
そして、出力層は0か1が出れば良いので、出力層の数は1つです。
したがって、入力層と出力層は、入出力ベクトルの次元に合わせる必要があります。
隠れ層はプログラマが調整する。
プログラマが調整するパラメータをハイパーパラメータと呼ぶ。
これはこの分野の専門用語です．
単純なMLPであっても，決めるべきパラメータは様々です．
例えば，隠れ層の場合．
例えば隠れ層の場合，この図では1つのニューロンしか示していませんが，2つ，3つと増やしていくことができます．
また，ニューロンの数も考慮する必要があります．
この図では3つのニューロンしかありませんが、10にも100にも増やすことができます。
さらに、活性化関数についてです。
先ほどのReLUのほかにもいろいろな活性化関数があります。
その中から最適な組み合わせを見つけていくことをハイパーパラメータ探索といい、プログラマが定義します。
一般に、層数やニューロン数が多いほど性能が高いと言われています。
しかし、一般に「学習が難しくなる」ことが知られている。
計算コストが純粋に高くなるからです。
トレードオフを調整しながら、良いネットワーク構造を見つけることが、設計者の腕の見せ所である。
活性化関数としては、シグモイド関数やハイパーボリックタンジェントなどが一般的に使われている。
活性化関数が非線形であれば、様々なものが使えるが、微分可能であることが必要である。
演習パートでは、Google Colaboratory（Colab）を使用します。
まず、Colabの設定方法について説明します。
まず、ColabをセットアップするためにGoogleドライブにアクセスしてください。
Googleドライブは、Googleのトップページから開くことができます。メニューからドライブのアイコンを選択してください。
Googleドライブを開き、演習用のフォルダを作成してください。そして、そのフォルダの中に配布されたipynbファイルをアップロードしてください。
初回のみ、Colabサービスを追加する必要があります。
左上の新しいアイコンボタンをクリックし、「Connect more apps」を選択してください。
Google Workspace Marketplaceの検索ボックスに colab と入力し、Colabアイコンをクリックしてください。
インストールボタンをクリックし、インストールしてください。
Googleアカウントを選択してください。
インストールが完了しました。
インストールが完了したら、ipynbファイルをダブルクリックすることでColabを起動することができます。
これがColabの画面です。
セル」を編集していきます。
セルには、「テキストセル」と「コードセル」の2種類があります。
テキストセルにはテキストを追加することができます。
コードセルにはコードを追加したり、コードを実行したりすることができます。
この2つのセルを使っていきます。
画面の左側には、目次（TOC）が表示されています。
ボタンをクリックすると、TOCを隠したり、消したりすることができます。
TOCの中の項目をクリックするとその場所にジャンプできます。
左側の一番下にあるアイコンをクリックすると、ファイルの管理ができます。
このファイルタブでは、ファイルのアップロードやダウンロードが可能です。
また、Google Driveに接続することができます。
Google Driveからファイルを取得したり、Google Driveにファイルをプッシュしたりすることができます。
ランタイム＞ランタイムタイプの変更をクリックすると、ノートブックの設定ウィンドウを開くことができます。このウィンドウでハードウェアアクセラレータを選択することができます。
None」、「GPU」、「TPU」が選択できます。
演習ではGPUを使用します。
それでは、演習の内容を説明したいと思います。
例題について説明します。
この例題では、MNISTデータセットをMLP（Multi-Layer Perceptron）により分類するプログラムを作成する予定です。
PyTorchを使用して、Deep Learning（DL）プログラムを作成します。この例は5つのステップで構成されています。
最初のステップ：ライブラリのインポート。
2番目のステップ。ネットワークを定義する。
3番目のステップ。エラー関数とオプティマイザを設定する。
第四のステップ データセットを設定する。
5番目のステップ ネットワークを学習する。
それでは、最初のステップをご覧ください。
これらのライブラリをインポートします。
ライブラリをインポートするためのコードを以下に示します。
import torch.nn as nn と書くことで、インポートすることができます。
torch.nn を nn と短縮することができます。
同様に「torch.nn.functional」を「FF」、「torch.optim」を「optim」と短縮することができます。
コードセルを実行してみましょう。
左上の再生ボタンをクリックするか、コントロールボタンを押しながらエンターボタンを押すと、コードを実行できます。
ここでは、エラーメッセージが出なかったので、プログラミングを続けることができます。
では、2番目のステップに進みましょう。
ネットワークを定義するためのクラスを作成します。
nn.Moduleというクラスを継承してクラスを作成します。
メソッドを2つ定義します。「init と forward です。
initメソッドでネットワークの構造を定義する。
forward メソッドでネットワークの順方向の伝搬を定義する。
これがネットワーク定義のコード・セルである。
このクラスは、nn.Module.Moduleを継承している。
initとforwardの2つの関数を持っています。
nn.Linearを使用して完全連結層を作成します。
活性化関数としてFF.ReLUを使っています。
ネットワークを定義する方法を説明します。
nn.Linearを使って、完全連結層を作ります。
nn.Linear関数は2つの引数を取ります。
最初の引数は入力サイズ、つまりニューロンの数です。
ここでは、写真の入力サイズである784を設定します。
第2引数は出力サイズです。
ここでは100とした。これは、ネットワークに100個のニューロンを持つ隠れ層があることを意味する。
また、層があります。
第1引数は100で、これは隠れ層の出力サイズに相当します。
第2引数は出力サイズである。
fc2 の出力はネットワークの出力である。
MNISTデータセットの出力は0から9までの数字である。
出力として10個のニューロンが必要なので、出力サイズとして10を設定した。
このようにネットワークの構造を設定することができる。
次に、forward関数を設定しましょう。
forward関数は、ネットワークの入力としてxという引数を持つ。
まず、ネットワークの第1層であるfc1でxを与える。
完全連結層では、インスタンス名の後の括弧内に入力を与えることで、順伝播の計算を行うことができる。
fc1 の戻り値はこの完全連結層の出力である。
その返り値を活性化関数ReLUに与える。
fc1の出力を与えることで、ReLUの出力を得ることができます。
次に、fc2にReLUの出力を与えることで、出力xを得ることができる。
最後に、前進関数はfc2の出力を返す。
このようにしてMPLを定義することができる。
ここでは定義されたクラスからインスタンスを作成します。
mlp.to(device)でGPU上でインスタンスを動作させることができます。
次に、エラー関数とオプティマイザの設定について説明します。
エラー関数としては、NN.MSELossやNN.CrossEntropyLossがよく使われます。
NN.MSELossは回帰問題で使用されます。
NN.CrossEntropyLossは分類問題で使用されます。
今回は画像の分類問題を解くので、NN.CrossEntropyLossを使用します。
optim.SGD (Stochastic Gradient Descent) または optim.Adam は、オプティマイザとしてよく使われます。
この例では、SGDを使用します。
criterionと呼ばれる誤差関数のインスタンスを作成します。
オプティマイザーの引数を設定します。
最初の引数には，学習させたいネットワークのパラメータを与えます．
ここでは、前のステップで定義されたMLPのパラメータを学習させます。
mlp.parameters()によって、学習用のパラメータを取得することができます。
第2引数には，学習率を与えます．
ここでは，0.01という値を設定します．
このようにして、誤差関数やオプティマイザを設定することができます。
これで、セルを実行することができました。
次に、4番目のステップに進む。
ここでは、MNISTデータセットをロードする。
MNISTデータセットは28x28のグレースケール画像である。
MNISTデータセットは、トレーニングデータセットとテストデータセットに分かれています。
トレーニング用には6万枚、テスト用には1万枚の画像を用意する。
また、バッチサイズも設定した。
バッチサイズとは、ネットワークに一度に与えるデータの数である。
データ数が多いほど、並列処理を行うため、学習時間が短くなります。
あまり大きな値を指定すると、メモリの使用量が増えるため、メモリエラーになります。適切な数値を設定してください。
逆に小さい数値を設定すると、バッチサイズが小さくなります。
反復回数を増やすと学習時間は長くなるが、メモリ使用量は少なくなる。
この2つのセルを実行することで、MNISTデータセットをダウンロードすることができます。
通常は、torchvision.datasets.MNIST を実行すると自動的にデータセットがダウンロードされる。
Colabのバグで、この機能からダウンロードしようとするとエラーになることがあります。
今回は、MNISTデータセットのディレクトリをダウンロードします。
このコードセルを実行して、MNISTデータセットをダウンロードしてください。
torchvision.datasets.MNISTが代わりにダウンロードしたデータセットをロードします。
このセルでは主に3つのことを設定します。
ここでは、画像の変換を行います。
データセットを transforms.ToTensor 関数でテンソル配列に変換しています。
PyTorchはテンソル配列を使って計算を行います。
ここではノーマライザーを使っています。
ダウンロードした画像の範囲、[0, 1]を[-1, 1]に変換しています。
次に、torchvision.dataset.MNIST でデータセットを読み込みます。
この関数は4つの引数を取ります。
第一引数はデータセットの場所です。
ここでは、カレントディレクトリを指定しています。
第2引数で学習用のデータセットであるかどうかを指定します。
trueを指定すると学習用データセットとして使用されます。falseを指定すると、テスト用に使用されます。
データセットをダウンロードするかどうかを指定しています。
今回はダウンロードする必要がないので、falseを指定します。
第4引数で、画像変換のプロパティを設定します。
最後の設定は、ミニバッチです。
ミニバッチの設定は torch.utils.data.Downloader で行うことができます。
第1引数にデータセットを指定します。
バッチサイズを第2引数で、データをシャッフルするかどうかを第2引数で指定します。
データの順番は学習性能に影響するため、学習データをシャッフルする必要があります。
学習データの順番は学習性能に影響を与えるので、偏りが生じないようにシャッフルする必要があります。
テストデータについては、データの順番はテストに影響しないので、シャッフルする必要はありません。
このようにデータセットを準備することができます。
では、最後のステップに進みましょう。
これはネットワークを学習させるためのステップである。
まず、入力データと理想的な出力データ（教師ありデータ）をネットワークに与える。
そして、差分値に対してネットワークの変数をリセットする。
実際の出力とネットワークの理想的な出力との差を計算する。
その後、バックプロパゲーションを実行し、ネットワークのパラメータを更新する。
これらのステップを繰り返し、ネットワークを学習させる。
これらは学習用のプログラムである。
まず、エポック数（データセットを何回繰り返すか）を指定します。
ここではエポック数が2なので、for文によりデータセットが2回繰り返されることになります。
このループの中で、バッチサイズごとに学習データセットが繰り返されます。
変数dataには，各繰り返しにおける学習の入力データとラベルが格納されます．
私たちはMLPに入力を与えます。
画像サイズを.view で変換する必要があります。
画像サイズは784でバッチの番号のサイズに変換されます。
GPUで学習を行います。
to(device)」でデバイスを指定する必要があります。
これは、ステップ2で定義したデバイスの設定です。
Cudaが利用できる場合はcuda0、そうでない場合はCPUがデバイスとなります。
GPUが利用可能であれば、入力とラベルはGPUに送られます。
前方伝播のためにMLPに入力を与えます。
ネットワークのインスタンスに入力を与えることで、順伝播の計算を行うことができます。
その戻り値が、ネットワークの出力となります。
次に，ネットワークパラメータの差分値をリセットします．
そして、誤差関数を計算する。
ステップ3で定義した基準の引数を2つ設定する。
第1引数はネットワークの実際の出力である。
第2引数は理想的な出力であるラベルである。
戻り値は誤差の値である。
バックプロパゲーションは loss.backword で計算することができる。
次に、オプティマイザーを使ってネットワークのパラメータを更新する。
optimizer.step によって行うことができる。
学習の進捗を確認するために、学習中の誤差を表示する。
ここでは、100回に1回の割合で表示しています。
誤差の値は loss.item で得ることができる。
損失の総和を計算する。
100回分の損失の平均値を表示する。
このプログラムでは、各エポックごとに学習した後、ネットワークのテストを行っています。
testloader_mnist は for 文で反復処理されます。
変数dataは入力とラベルを持つ。
同様に変換された画像を GPU に送る。
そして、MILから出力を得る。
実際の出力と理想の出力を基準にして、誤差を求めます。
逆算しなくても、criterion.item で損失が得られます。
テストの損失はサムアップされる。
ネットワークの出力からラベルを取得する。
outputs.argmax でネットワークの最大出力を確認する。
実際の出力と理想的な出力を比較し、精度を計算する。
pred.eq にラベルを与えることで、実際の出力と理想的な出力を比較することができる。
正解の数を合計して正解とする。
繰り返し計算の結果、精度を得ることができる。
さて、このコードセルを実行してみましょう。
100回に1回、誤差関数の出力が得られる。
各エポックの終了時に精度を得ることができます。
これで2エポック分の学習が終了しました。
その結果、この例で定義したネットワークの精度は89%になりました。
昨今のディープラーニングブームで、私たちの身の回りにはAIを応用した製品やデバイスがたくさんあります。
例えば、スマートフォンやAIスピーカーなどがあります。
このAIを開発するための環境も非常に充実しています。
例えば、プログラミングフレームワークには、PyTorch,
Chainer、Keras、TensorFlowなどがあります。
その中には、すでに開発が終了しているものもあります。
ChainerはPyTorchを後継として開発を終了しています。
また、大企業が提供するクラウドサービスも充実しています。
よく知られているのは、Amazon、Google、Microsoftが提供しているものです。
これらが提供するクラウドサービスを利用すれば
自社の製品やサービスにAI機能を取り入れることができます。
プログラミングそのものはできなくても
AIが一般化し、プログラミング環境が充実した状況で必要とされるのは、こうした人材ではありません
と、プログラミング環境が充実してきました。
例えば、ディープラーニングの理論を理解している人。
あるいは、ディープラーニングのことはよくわからないけど、プログラミングはできるし、ツールも使えるという人。
必要な人材は、ディープラーニングの仕組みを理解している人。
ライブラリを使って実装できる技術を持っていて、性能向上のためのチューニングができる人です。
近年、この機械翻訳が非常に発展していると言われています。
これらはニューラルネットワークを利用した機械翻訳です。
例えば、DeepLやGoogle翻訳などは、非常に精度が高いと言われています。
これらのツールは、非常に自然に言語を翻訳することができます。
また、これらのツールをうまく活用して、英字新聞や論文を読んでみましょう。
AIは、自律走行やADAS（先進運転支援システム）にも大きく関わってくると言われています。
これはNVIDIAの場合ですが、ディープラーニングとGPUアクセラレーションを利用して、道路標識の検出。
信号、停止線などをこのように
人間の目に代わる機能をコンピュータが実現することが可能になりつつあるのです。
一般的な画像認識の例を紹介します。
入力された画像のカテゴリーを推測する問題です。
この例は、2012年にディープラーニングが注目されるきっかけとなった国際的な画像認識コンテストの結果です。
例えば、このトラの写真を見せると
コンピュータは「虎だ」と答えます。
テレビの写真を見せれば、コンピューターは「テレビだ」と答えるでしょう。
しかし、左上のコアラの画像では、コンピュータはウォンバットと答えます。
間違えても、人間と同じように間違えます。
もう10年も前の話です。
このコンテストがきっかけで、Deep Neural Networkが急速に発展したと言われています。
先ほどの一般的な画像認識を提供しているのが、このGoogle Cloud Vision API
は、先ほどの一般的な画像認識をクラウドサービスとして提供するものです。
クラウドベースの画像認識を実現するAPIです。
ディープラーニングや画像認識の仕組みを詳しく知らなくても、サービスに利用することは可能です。
例えば、人物の顔を検出する機能を追加し
とか、その人が今どんな表情をしているのかを認識する機能を追加することができます。
私たちの周りには、たくさんのAI活用事例があります。
実際にしばらく使ってみることで、Webアプリケーションで簡単に体験することができます。ぜひ試してみてください。
まず1件目は、先ほど紹介したGoogle Cloud Vision APIです。
こちらのURLからアクセスできます。
アップロードした画像から見えるものを回答するAIを試してみてはいかがでしょうか。
例えば、左上の画像をアップロードした場合。
は、その画像のカテゴリーを返します。
例えば、「映っている」「自然が映っている」「水が映っている」とAIが答えます。
カテゴリ認識の精度が高いことが分かります。
左下の例では、画像に写っている文字が認識されています。
このように簡単に試すことができますので、ぜひご自身で試してみてください。
もう一つの例として、線画に自動的に色をつける例です。
NVIDIA Jetson AI Certificationを試してみませんか？
これは、NVIDIAが発行しているCertificationです。
例えば、就職などで履歴書を作成する際に、資格として記載することができます。
本講座では、自由な発想でAIを使ったプロジェクトを実施します。
本講座の最終課題として、このNVIDIA認定資格に挑戦することができます。
また、NVIDIA Japanの日本人スタッフによるサポートも受けられます。
日本語、英語ともに対応可能だと思います。
このAIセミナーの参加者は、NVIDIAのスタッフからサポートを受けることができます。
プロジェクト終了時に英文レポートを提出する必要があります。
その際、英文レポートの校正が必要な場合は、大学側が校正料をサポートします。
また、小型ロボット「TurtleBot」を貸与します。
そして、組み込み型GPUのJetson NANO。
このプロジェクトの最終タスクに必要な
これが今回のプロジェクトの流れです。
トレーニングの段階は、このAIセミナーの講義
またはNVIDIAのホームページのイントロビデオを見ることでトレーニングができます。
次のプロジェクトベースの評価は、この講義の最終プロジェクトになります。
プロジェクトベースの評価のレポートは、NVIDIAで評価されます。
プロジェクト評価に必要な機材は弊社でサポートします。
レポート作成のための英文校正費用
また、このNVIDIA本社への応募の際には、NVIDIAの社員によるサポートも受けられます。
ご興味のある方は、こちらのホームページをご覧ください。
詳細な情報を入手することができます。
これは日本語の記事です。
ロボスタによるこの資格の記事です。
興味のある方は、ご自分で検索して読んでみてください。
このロボスタの方々は、人がマスクをしているかどうかを判断するAIを作りました。
Jetson AI Specialistは、彼らに日本初の認定を受けました。
では、ニューラルネットワークのトレーニングについて説明します。
ニューラルネットワークの訓練は...
で、ニューラルネットワークが望ましい入出力関係を近似できるように、最適な重みとバイアスを計算することです。
重みは、この図の丸を結ぶ矢印で示されています。
式中、重みはWとbに相当する。
多層パーセプトロンの場合。
隠れ層と出力層の間のパラメータを学習します。
XORの例で考えてみましょう。
を入力とし、[0, 0], [0, 1], [1, 0], [1, 1]を入力とします。
XORが正しく出力されるように、Wとbを計算する。
ネットワークの規模が小さい場合は、パラメータ値を手で探して設定すればよい。
ネットワークの規模が大きいと、人間が勝手にパラメータを設定することはできない。
そこで、データを使ってネットワークを学習させる。
ネットワークを学習させるためには、以下のような誤差の変化を計算する。
という誤差の変化を計算し、NNの重みとバイアスを変えて、実際の出力と目的の出力との誤差を計算する。
そして、誤差が小さくなるようにパラメータを調整する。
バックプロパゲーションを用いて、誤差の変化を求める。
誤差が最小になるように重みとバイアスを調整することを最適化といいます。
右の図では、横軸が重みとバイアス、縦軸が誤差を表しています。
データを与えて見てみましょう。
この例は、画像認識によく使われるFashion-MNISTというデータセットです。
データは一般的に、トレーニング、バリデーション、テストの3種類に分けられます。
学習データは、モデルの重みとバイアスを更新するために使われます。
検証データは、モデルの更新には使用されない。
検証データはモデルの更新には使わず、モデルの評価と学習の調整に使われる。
したがって、ニューラルネットワークの学習は、学習データと検証データによって行われる。
ネットワークが学習された後
学習後のモデルの汎化性能をテストデータセットで評価します。
このとき、データがトレーニング、バリデーション、テストに分けられていることを確認してください。
次に、学習データの与え方を決める単語、batch、epochについて説明します。
ミニバッチと呼ばれる単位でデータを与えます。
この例で考えてみましょう。
ここでは、バッチサイズが10なので、10枚の画像が同時に与えられます。
バッチサイズは重要です。ある程度まとめてデータを渡した方が良いと言われています。
しかし、バッチサイズが大きすぎると、GPUのメモリ不足でプログラムが動かなくなることがあります。
バッチサイズを調整する必要があります。
この例では、データセットを8つのmini-Batchに分割しています。
すべての学習データを投入することをエポックと呼びます。
バッチ、バッチサイズ、エポックという重要な用語の意味を、この図を使って理解してください。
次に、学習方法であるバックプロパゲーションについて説明します。
バックプロパゲーションは、重みとバイアスに対する誤差関数の勾配を計算する方法である。
つまり、微分値を計算するのである。
誤差関数は、ニューラルネットワークの実際の出力と所望の出力との誤差を定義するものである。
この関数は、誤差が大きい場合に大きな値を出力する。
例えば、回帰タスクの場合、平均二乗誤差を用いる。
回帰タスクは、連続的に変化する値を予測するタスクである。
例えば、気温の予測は回帰タスクである。
分類タスクの場合は、クロスエントロピーの誤差関数がよく使われる。
分類タスクとは、データがどのクラスに属するかを予測するタスクである。
例えば、「1」という数字の画像をネットワークに見せると、「1」というクラスのニューロンが活性化されます。
では、バックプロパゲーション法を計算してみましょう。
3層MLPを例にとります。
これは，入力層，隠れ層，出力層から構成されています．
ニューロンのインデックスはそれぞれi,j,kです。
ここで，順伝播の計算を確認しておきましょう．
入力層から出力層への計算を順伝播と呼びます。
XORタスクの例と同様である。
まず、入力-隠蔽層間で累積入力xと重みwを掛け合わせ、バイアスをかける。
その後、非線形関数を適用する。
隠れ層の値が入力層の出力となる。
隠れ層から出力層への計算は、隠れ層の出力を用いて行われる。
同様に、乗積演算と非線形関数を適用する。
値が出力されたら、実際の出力と所望の出力との差を求める。
つまり、実際の出力と監視データを比較するのである。
その差を求めるのに、誤差関数を使う。
誤差関数を2種類見てみましょう。
まず、平均二乗誤差関数です。
これは回帰処理に使われる。
目的の出力(t)は監視信号として与えられる。
2つ目はクロスエントロピー誤差関数である。
この場合、正解tはラベルとして与えられる。
ラベルでは、正しいクラスは 1、それ以外は 0 で表現される。
誤差関数を用いて、実際の出力と目標との誤差を測定する。
誤差を測定した後、バックプロパゲーションを適用する。
バックプロパゲーションは、出力層から入力層への計算処理である。
誤差関数の出力の偏導関数を w に関して計算する。
偏導関数は、3つの偏導関数の積に展開される。
展開された偏微分方程式は図のように対応する。
この方程式の2番目と3番目の偏導関数をデルタkに置き換える。
黄色の部分の1つ目について考えてみよう。
この部分には、出力層と隠れ層から複数の誤差が流れ込んでいます。
それを踏まえて式を考える必要があります。
実際の出力と目標との誤差は、後方に伝搬させることができます。
ただし、逆伝播の計算は複雑なので、その点は注意が必要です。
最近の深層学習フレームワークでは、計算グラフを用いた逆モード微分法が採用されています。
逆伝搬は、逆モード微分を用いてフレームワークが自動的に計算する。
これにより、プログラマーは簡単にネットワークを定義することができる。
これはフレームワークを利用する大きなメリットの一つである。
このクラスでは、この操作を手動で計算することはありません。
階層構造を計算することにより、出力であるyを得ることができます。
バックプロパゲーションは非常に複雑です。
L, g, ...の導関数を計算する必要がある．
計算グラフのすべての要素が微分可能であれば
が自動的に差分を計算します。
活性化関数g1,g2は微分可能であると述べました。
したがって、誤差関数も非線形活性化関数も微分可能でなければ、バックプロパゲーションの計算はできない。
逆モード微分の仕組みを簡単に説明する。
簡単な例で考えてみよう。
計算グラフとは、演算とデータをノードとエッジで表現したものである。
ノードはデータと基本的な算術演算を表す。
矢印で示される辺は、計算結果の流れを表している。
例えば、a×b＋c×dを計算するとしよう。
対応するグラフをスライドに示します。
図のgにはa×b＋c×dの計算結果が記入されています。
逆モード微分の仕組みについて考えてみましょう。
式中、a×b＋c×d。
a x bはグラフのeに相当する。
c×dはfに対応する。
e＋fの結果はgに対応する。
入力a,b,c,dに対して、それぞれ3,2,4,5が入力であると仮定する。
次に、計算グラフの各部を微分することを考える。
まず、一番右の部分であるgを考える。
gに関して偏微分した結果は「1」である。
ここから逆算して考える。
gとeの間で考える場合、gをeで微分することで答えが得られます。
g = e + fなので、e + fをeで微分すると結果は1です。
同様に、e＋fをfで微分するとiとなる。
eとaの間で考えるときは、eをaに関して偏微分すれば答えが求まる。
同様に、e＝a×bなので、eをaに関して偏微分した結果はbとなる。
bは2なので，この部分は2となる。
同じようにして，すべての辺の微分値を計算することができる．
連鎖法則の考えを見てみよう。
すべての辺の微分値がわかっていれば
aに関するgの偏微分を連鎖法則で計算することができる。
エッジの値を用いて計算することができる。
gの偏微分を元の式を使って計算するのは難しい。
しかし、計算グラフと連鎖法則を用いれば簡単に求めることができる。
gのaに関する偏微分の結果は、1* 2 = 2と求まる。
これはニューラルネットワークの計算グラフの例である。
x と w を積算する。
を積算し、目標値を与える。
すべての微分は、この計算グラフを用いて、逆モード微分で解くことができます。
プログラマがフィードフォワード伝搬と誤差関数を定義すると、ディープニューラルネットワークの枠組みで
ディープニューラルネットワークのフレームワークを用いて
フレームワークが自動的にグラフを計算する。
また、すべての勾配を得るための逆モード微分も計算する。
ただし、プログラマーはフレームワークの仕組みを考える必要がある。
バックプロパゲーションと逆モード微分の仕組みは説明しましたが。
フレームワークを使うことで、ディープニューラルネットワークのプログラミングが容易になります。

さて、AIセミナーの講義パートを始めましょう。
今日のテーマは、「注意」というメカニズムです。
まず、「注意」を説明し、次に「自己注意」を説明します。
アテンションは最近流行っている仕組みです。
アテンションはCNNと組み合わせて使われます。
CNNと組み合わせることで、比較的簡単な構造で性能を向上させることができる。
Attentionはニューラルネットワークの広い分野で利用されている。
ここでは、Attentionの概要について説明する。
まず第一段階として、CNNを用いて多くの入力データから簡単な特徴を抽出する。
第2ステップでは、入力から生成された特徴量を全て使うわけではありません。そこで、ネットワークはそのうちのいくつかに着目する。
そして、フォーカスされた特徴はニューラルネットワークの推論に使われる。
データの一部、つまり特徴に焦点を当てるので、Attentionと呼ばれる。
Attentionは自然言語処理の分野で発展してきた仕組みである。
簡単な例として、画像処理を紹介したい。
CNNを用いた画像認識について考えてみよう。
寿司の画像を例にとって考えてみよう。
寿司画像は物体認識の問題として考える。
これはブリ（鰤）の画像である。
人間は画像のブリの部分だけを見れば、その物体がブリかどうかを判断できる。
通常のCNNの場合、画像全体が入力としてネットワークに与えられます。
そのため、画像認識は背景の領域に非常に敏感です。
この画像は、黒いお皿の上に「ぶり」が乗っています。
お皿の色が変わっても、お皿の上のお寿司は同じです。
お皿の色がどうであれ、「ぶり」という答えを期待するのです。
ネットワークには背景のある画像が与えられるので、出力は背景の影響を受ける。
この影響を軽減するために、人間の注意力であるフォーカス機構を画像処理に導入しています。
ここでは、画像の寿司だけに注目する方法を考える。
これが画像処理分野における「注意」の概念である。
まず、入力画像から簡単な特徴量を抽出する。
次に、関心領域を推定するニューラルネットワークに分岐する。
このマスク画像のように、CNNから関心領域を推定するマスクを取得する。
この注目領域の画像で入力画像をマスクする。
すると、左下の画像のように、寿司の部分のみを抽出することができる。
このように、寿司の部分だけを抽出することで、後段で背景を無視した物体認識を構築することができる。
以上が画像認識分野におけるアテンションの一例です。
画像処理におけるアテンションは、もっとわかりやすい。
アテンションとは、関心領域を推定する仕組みである。
これは簡単な例であった。
通常のCNNで考えてみよう。
CNNの最初のステージで作成された特徴マップにアテンションを適用する。
この概念をSqueeze-and-Excitation Network (SENet)という。
SENet はマスク情報を構築し、各特徴量マップの関心領域を推定する。
この例では、1つ目の特徴マップと3つ目の特徴マップが認識上重要である。
そこで、1番目と3番目のマップに対してマスクを構築し、注目する特徴を推定する。
構築したマスクを元の入力画像に適用することで、このような特徴マップ群を得ることができる。
これらの特徴マップは、後段のニューラルネットワークに使用される。
以上で画像処理のAttentionの説明は終わりです。
次に、アテンションが元々開発された自然言語処理の分野でのアテンションを見てみよう。
これは文章を分類するネットワークでのAttentionの例である。
例として、入力文が肯定的な感情か否定的な感情かを判断する文の分類の問題を考えてみる。
入力文を単語に区切り、各単語の特徴量を出力する。
すると、一般にCNNやRNNは、正負のラベル情報を直接推定する。
Attention機構を導入することで、判断に有用な単語の特徴のみを抽出することが可能である
を抽出し、その特徴量に基づいて推定を行うことができる。
この例では、「おいしい」という単語が有用である。
この単語は、肯定的か否定的かの判断に大きな影響を与える。
したがって、この単語だけに注目し、他の単語は出力にほとんど影響を与えない。
このように、Attentionは文の分類に応用することができる。
次に、翻訳の例について考えてみよう。
これはAttentionを用いずにLSTMを用いて翻訳を行った例である。
どのように翻訳が行われるかを説明する。
前の例と同様に、文を単語に区切り、各単語に対してLSTMを用いて特徴量を生成する。
特徴量の生成にはエンコーダを用いる。
これはLSTMの時間発展型モデル（Sequence to Sequence）に基づいている。
このモデルでは、すべての単語の特徴を抽出する。
そして、モデルは原文全体の特徴量から翻訳後のテキストを生成する。
デコーダはそのテキストを文頭から単語単位で翻訳していく。
アテンションなしの翻訳は、このような仕組みになっている。
人間がこの文章を翻訳するとき、最初から文章全体を見ることはない。
次に、Attentionを使った翻訳を説明します。
私たち人間は、この文章を翻訳するとき、最初から文章全体を見ているわけではありません。
例えば、文中の主語をまず探します。
例えば、「ぶり」という単語に注目してみましょう。
この場合、「ぶり」という特徴を利用して訳語を作ります。
アテンションは、人間が翻訳するのと同じようなことができる。
これは、前の画像の例と似ています。
まず、各単語の特徴を抽出する。
そして、先ほどのデコーダーの出力とエンコーダーの出力を掛け合わせ、ソフトマックスを適用する。
そうすることで、どの単語に注目するかを決めることができる。
この例では、2番目の単語である「ぶり」に着目することが決定される。
そして、「ぶり」という特徴量をもとに、出力する単語を決定している。
各ステップで注目する単語を決定するために、アテンションが使われる。
このようなプロセスを経て、Attentionを使った翻訳後の文章ができあがる。
アテンションを使って翻訳の精度を上げる例を紹介する。
精度を上げるために、Query-Key-Valueを用いたSource-Target Attentionが提案された。
このモデルでは、エンコーダが検索用にKeyという素性を出力し、実際の翻訳用にValueという素性を出力する。
つまり、Encoderの出力を分離するためのモデルである。
先ほどの例と同様に、Decoderも素性を持つ。
このモデルでは、Decoderの素性はQueryと呼ばれる。
前の例と同様に、Decoderの最初の単語を決定してみよう。
最初の単語はQueryとして与えられる。
そして、最初の単語に対するすべてのキーの応答をチェックする。
Keyのレスポンスが最も大きい単語のValueを使ってFeatureを作成する。
作成した特徴量を元に、次の単語の翻訳単語を決定する。
では、その手順を順番に見ていこう。
まず、対象のQueryに全単語のKeyを掛け合わせる。
乗算結果が最も高い単語に注目する。
これにより、注目する領域の特徴量の効果が高まり、他の領域の特徴量の効果が減少する。
そして、この注目によって得られた特徴量を用いて、翻訳された単語を作成する。
これがソース・ターゲット注目の仕組みである。
次に、自己注意をみてみよう。
先に説明したソース・ターゲット注目の場合、Key / ValueとQueryは異なるソースから生成される。
翻訳の例では、Key / ValueはEncodeから、QueryはDecoderから生成される。
Self-Attentionの場合、Key/ValueとQueryは同じソースから生成される。
そこで、Self-Attentionは、自ら生成したKey/Queryを用いて、自ら生成したValueに重み付けを行い、合計する。
文中のSelf-Attentionの例をこの図に示す。
Self-Attentionは、Encoder側で特徴量間の関係を考慮することができる。
このブリはおいしい」という文では、おいしい という単語が ブリ を特徴づけている。
このブリはまずい」という文の場合、不味い という単語が ブリ を特徴付けている。
おいしい や 不味い という単語は、前の単語 ブリ を特徴付けると考えられる。
つまり、入力データの単語間の関係性を考慮することができる。
Self-Attentionのポイントは、入力データ中の関係性に着目できることである。
Self-Attentionの例を見てみよう。
まず、Queryと処理対象の単語のすべてのKeyの内積を取る。
ここでは、「ブリ」に着目し、Queryの周辺にある他のKeyを参照する。
最も関連性の高い単語である「delicious」に着目する。
そして、各単語からValueを受け取る。
Valueを受け取ると、重みが高いほど反映されるように重み付けを行う。
そして、最終的な特徴を作る。
Attention後の情報は、入力された単語と重み付けされたValueの和である。
このように、Self-Attentionは文中の単語間の関係を抽出することができる。
自然言語処理の分野でのSelf-Attentionの例を説明する。
Self-Attentionは、画像処理にも応用できる。
ニューラルネットワークによって抽出された特徴マップの集合から、各Query Key Valueを生成する。
自然言語の場合と同様に、QueryとKeyから重要な部分を探す。
そして、その値を重み付けして合計する。
そして、重み付け和から得られた特徴を、元データの特徴に追加する。
このように、重要な特徴に着目することで、Attentionを画像処理に応用することができる。
Self-Attentionを画像に利用するメリットを説明する。
まず、離れた場所にある特徴量を考慮することができる。
画像に写っているブリはおいしいか？という分類問題を解くニューラルネットワークを考えてみましょう。
左の入力画像では
はブリが小さく、通常のCNNでは分類が困難です。
しかし、空間的に離れた場所にある「華麗な笑顔」という情報を使って「ぶり」を特徴付けることができれば...。
は、ブリが美味しい と推論することが可能になる。
もし、笑顔の素敵な男性が写っていなかったら、ブリ が美味しいかどうか判断できないかもしれません。
仮にいたとしても、「笑顔の素敵な男性」と「ぶり」は、通常のCNNでは遠すぎるため、この問題を解決することは難しい。
しかし、Self-Attentionの仕組みを応用すれば、空間的に離れた画像特徴量を組み合わせることができる。
それらを組み合わせることで、「ブリが美味しい」と推論できるかもしれない。
現在、自然言語処理や画像処理など、さまざまな応用分野を持つAttentionを見てきました。
みなさん、こんにちは。AIセミナーを始めましょう。
本日のトピックは深層強化学習で、AIセミナーの最後のトピックになります。
深層強化学習を見る前に、まず強化学習の概要を見てみましょう。
そして、強化学習の問題をディープラーニングでどう解決するか。
そして、その後、演習に取り組みましょう。
まず、強化学習(RL)の構成要素を見てみましょう。
RLの構成要素の1つは環境です。
環境には状態が含まれています。
また、RLはエージェントで構成される。
RLのエージェントの例としては、ロボットや自動運転車などがあります。
エージェントは、自分の行動を決定するポリシーを持っている。
エージェントは、何らかの方法で環境の状態や状況を観察する。
エージェントは与えられた状況によって決定されたポリシーに基づいて行動する。
エージェントが行動を起こした後，環境は変化する．その変化した状態を観察し，次の行動を起こす．
RLはエージェントと環境との相互作用によって動作する。
この学習方法は、本講義で見てきた一般的なニューラルネットワーク...とは根本的に異なる。
この講義を通して見てきた
最も重要な点は、環境とエージェントの相互作用である。
RLには報酬という概念がある。エージェントは、例えば宝探しのような環境の中で活動する。(この例については後述する）。
エージェントは、宝を見つけることができれば、その良し悪しを示す報酬を受け取る。
行動履歴は報酬によって更新され、エージェントは少しずつ賢くなっていく。
これがRLの全体的な枠組みである。
機械学習は主に3つのカテゴリーに分けられる。1つ目は教師あり学習で、CNN、RNN、MLPなどがあります。
2つ目は教師なし学習で、例えばAEやGANなどがあります。
3つ目は強化学習（RL）です。
RL学習法の考え方は、教師あり学習とも教師なし学習とも根本的に異なる。
強化学習と教師あり学習の違いを見てみよう。
教師あり学習で、エージェントの行動を生成する方法を考えてみよう。
エージェントは蓄積された行動から結果を出力する。
それぞれの行動に対して、教師あり信号を作成することができれば
教師あり学習により、エージェントの行動を学習することができる。
結果は複数の行動の結果であるため。
最終的な結果に対して、各行動に対して正確な教師信号を与えることは困難である。
そのため，教師あり学習はエージェントを訓練する上で限界がある．
そこで、強化学習では、各行動にラベルをつけない。
報酬は一連の行動の結果として与えられる。
例えば、野球の打者ロボットを考えてみよう。
バットの振り方、振り角、スピードなど、すべてのデータの系列に対して、教師データを与えることは困難です。
しかし、行動の結果に対して報酬を与えることは簡単です。
例えば、ヒットを打ったらご褒美をあげる、ホームランを打ったらご褒美をあげる。
結果に対してのみ報酬を与えることが、他の学習方法との違いです。
RLは結果のみを評価するため、比較的容易に報酬を与えることができる。RLは、例えば野球のバッティングマシンのような多くのフレームワークで活用することができる。
エージェントは報酬を得たときの行動履歴を評価することで、その経験から方針を獲得することができる。
ここが教師あり学習と強化学習の大きな違いである。
ここからは、ある例を見て、RLの詳細を理解することにしよう。
この単純な迷路の問題を考えてみよう。このロボットは白い細胞の上を移動することができる。
このロボットが宝箱を見つけるのは良いことだ。
しかし、爆弾を見つけてしまうと、爆弾が爆発してゲームオーバーになります。
宝箱のマスには＋1点の報酬があり、一方、爆弾のマスには-1点の負の報酬がある。
この図では、ロボットがエージェントで、迷路が環境である。
ロボットは白いセルを移動しながら宝物を探します。
例えば、ロボットが左下にいるとき、上に行くか右に行くかはポリシーによって決定される。
ロボットが「s」という状態にあるとする。
この例では、状態 s はマップ内の座標のようなものです。この迷路には12個のセルがあるので
「s は12通りの状態を取ることができます。
例えば、ロボットが左下の状態 s にいるとします。
最適な行動は「上に行くのが良い」かもしれない。この最適な行動は、ポリシーによって決定される。
方針は関数で表現される。この例では、ポリシーは状態 s の関数πである。
アクションは、ポリシーによって与えられます。この例では，行動 a は Go up である．
状態 s で行動 a から得られる報酬を定義する．
この例では，報酬は宝箱が+1点，爆弾が-1点である．
例えば、左の角にいるロボットは、「右」「右」「右」「上」「右」と行動します。
すると、マイナスの報酬を得ることができる。
これがエピソードです。
エピソードとは、開始から終了までの期間のことです。
このように、環境、状態、エージェント、方針、行動、報酬というのが強化学習の基本的な枠組みである。
次に、モデルをどのように学習させるかを見てみよう。
状態-行動の価値関数である「Q」値について考えてみよう。
この問題では、ロボットは上下左右に動くことができる。
各状態で上下左右に進む確率はこの例のようになる。
左下のセルを状態「s0」と呼び、この例では他に状態「s1」「s2」「s3」「s4」などがある。
行動の値はQ関数で表される。
値を大きくすることができる最適な行動は、各セルの赤色で示される。
この例から、正の報酬を得るための最適な行動は、「上」「上」「右」「右」「右」であることがわかる。
この一連の行動は、報酬の総和の期待値が最も高くなる。
爆弾の隣のセルの Q 値は負である。
爆弾のセルに移動すると値が下がることをQ関数で表現している。
良いQ関数が獲得できれば，最も高い値を引き起こす政策を選択することで問題を解決することができる．
エージェントは負の値を選ばない限り，爆弾にぶつかることはない．
最適化されたQ関数が得られれば，エージェントは容易に宝箱を見つけることができる．
次に，Q 学習について見てみよう．
まず、各セルの値は一様またはランダムに初期化される。
次に、得られた値でQ関数を更新する。
学習には1回あたりの割引を適用する。
宝箱を発見する前の行動には、比較的大きな報酬が伝搬される。
ゴールから遠ざかれば遠ざかるほど、より大きな割引が適用される。
左下の例を見てみよう。初期位置 s0 から右へ移動するとき。
報酬は1であり、割引率は1より小さい。
しかし、「下」「右」「上」の3ステップで宝箱を見つけることも可能である。
このように行動し、Q関数が更新されれば。
学習率、更新率はαで決定されることになる。
このとき、割引後の報酬であるγは、この3つのステップで与えられる。
s0 において、エージェントは下へ移動するよりも右へ移動する方がより多くの報酬を得ることができる。
エージェントはこの方法で報酬を獲得し，Q値を更新する．
これが元のQ値である．Q関数は、報酬の量から決定されるパラメータで更新される。
この例では、エージェントが爆弾に当たってゲームオーバーになりました。
このエピソードを何百回、何千回と繰り返すことで
宝箱を見つけることができれば、Q関数は正の値に更新されます。
エージェントが爆弾に当たったエピソードは、負の報酬で更新されるため、負の値が蓄積される。
このように、バランスの取れた良いQ関数が獲得できることが期待されます。
環境地図ができれば、ロボットは思い通りに動けるようになります。
報酬を決めることができれば、複雑なエージェントも学習させることができる。
RLモデルは、教師あり学習や教師なし学習とは全く異なる枠組みで学習することができる。
強化学習は、そもそも報酬を決めることができれば、これほど幅広い分野に応用できるのである。
という応用の可能性も秘めていた。
強化学習やQ学習はかなり以前から研究されていたが、うまくいかなかった。
例えば、Q学習では探索空間の次元が高いことが問題である。
例えば、10×10ピクセルの2値画像について考えてみよう。
この例では、画像だけを使ってレガシーピンポンゲームを学習してみよう。
10×10の2値画像でも、組み合わせは2の100乗個。10の30乗個という膨大な状態を持っています。
Q値を全てカバーするように学習させるためには、十分な計算メモリと十分なサンプルを確保することが困難である。
ただし、先の迷路問題（12状態）は解ける可能性がある。
10×10ピクセルの2値画像さえも扱える問題は解けない。
そこで、Qを均等に分割するのではなく、Qの近似関数を解として導入する。
目標値を設定し、損失関数を定義して、勾配法によりパラメータthetaを学習させる。
これが深層強化学習である。
これによって、Q学習の状態分割を深層学習で置き換える。
深層学習でパラメータを学習することで、Qを近似するのである。
画像を10×10ピクセルに分割して一律に学習するのではなく
得られたネットワークをQ関数として、例えばCNNを用いた画像の学習を行う。
Qをディープラーニングのパラメータと同数で近似させればよい。
そうすることで、データの分割方法を学習し、報酬によってパラメータが更新されるようになります。
その結果、状態を表現する能力が高まる...。
となり、実用的なメモリ量と計算時間で様々な問題を解決できるようになります。
そして、これらの技術を訓練に利用する。
また、割引率であるγを定義しておく。
ε-greedy法がどの程度ランダムに動くかを記述することができる。
ε-グリード法を入れない場合、ランダムに生成される初期値の影響を受ける動作がある可能性がある。
ある確率εで、Q関数と相関のない振る舞いをする。
ある確率εでQ関数と無関係な振る舞いをする、つまり、今まで経験したことのない新しい行動をとるようになる。
ε-greedy法は重要である。ランダムな行動を与える最も簡単な方法である。
ランダムに行動することで、広大な環境を探索することができる。
貪欲法では、既知の行動の中で最も価値のあるものだけを取る。
ε-greedy法では、εが小さいと、ほとんどの場合、貪欲な行動をとる。
また、ε-greedy法では、εが小さいと、ほとんどの場合、欲張りな行動を取り、時々、別の方法を探す。
その結果、今まで探索されなかった最適な経路を見つけることができるかもしれない。
経験値再生は、経験をメモリに蓄積する機能である。
先の例では、数百、数千のエピソードを繰り返すことで学習させる。
これらのエピソードを記憶し、ランダムにサンプリングすることで、学習データの偏りを防ぐことができる。
私たちの海馬も、経験値再生と似たような機能を持っていると言われています。
演習に取り組みましょう。TAに気軽に質問してください。
以上で本日の講義は終了です。
次に、最適化について説明する。
バックプロパゲーションで求めた重みとバイアスをわずかに更新し
を勾配の負の方向へ繰り返し更新していく．
より誤差の少ない部分を探すことを最適化と呼びます。
更新の度合いを決めるパラメータを学習率と呼びます。
最適化の方法には様々なものがあります。
最も基本的な最適化アルゴリズムは確率的勾配降下法(SGD)です。
性能は良いのですが、学習速度が遅いのが難点です。
Adamも有名な最適化です。
学習速度が学習中に変化する。
SGDの改良版と言われています。
複数の最適化アルゴリズムを組み合わせている。
このアルゴリズムは効率的なので、学習速度が速い。
最適化アルゴリズムの詳細については、本講義では説明しません。
興味のある方は、参考文献に詳しい説明がありますので、ご確認ください。
最適化のプロセスを説明します。
まず、学習データからミニバッチを取得します。
そして、そのデータをネットワークに与え、順伝播法を実行する。
次に、ネットワークからの実際の出力と、望ましい出力である監視信号との誤差を計算する。
勾配用の変数を初期化し、バックプロパゲーションにより重みとバイアスの勾配を計算する。
勾配は変数に蓄積される。
最後に、最適化アルゴリズムによって重みとバイアスが更新される。
そして、次のミニバッチに移る。
このような最適化のプロセスが何度も繰り返される。
次に、正則化について説明します。
ニューラルネットワークを学習する際に、オーバーフィッティングが発生します。
学習データセットに対して過度に最適化されると、ニューラルネットワークはテストデータを正しく予測できなくなります。
テストデータセットを予測できない場合、オーバーフィッティングが原因である可能性がある。
オーバーフィッティングは、学習データセットを正しく分類できたとしても、テストデータセットを予測できない場合の原因である。
基本的に、モデルの複雑さが増すと、学習誤差は減少する。
このとき，誤差が大きくなるポイントがあることが実験的に知られている．
横軸はモデルの複雑さである分散である．
モデルの複雑さとは、ニューロンや層の数である。
私たちは、真のモデルからの誤差であるバイアスを最小にしたいのです。
ニューラルネットワークをある程度大きくすると、バイアスは減少する。
グラフの右側でオーバーフィッティングが起きていると考えられる。
オーバーフィッティングを防ぐ方法として正則化がある。
学習誤差は大きくなるが、テストデータの誤差である分散の増加を抑えようとする方法である。
汎化誤差とは、真の分布とモデルとの間の誤差のことである。
実際の真の分布はどうやってもわからない。
そこで、テストデータからの誤差を汎化誤差と呼ぶことにします。
正則化はモデルの分散を小さくし、バイアスの上昇を抑制する。
正則化のアルゴリズムには様々なものがある。
例えば、early stopping。モデルがオーバーフィットする前に学習を停止させる。
この方法は、オーバーフィットする前に学習ループを停止させる。
また、L1ノルムやL2ノルムの正則化もよく使われます。
この方法では、誤差関数に重みのペナルティ項を設定する。
重みの値を大きくしないようにする。
また、重みを疎にすることもできる。
そして、モデルの分散を小さくすることができる。
ドロップアウトもよく使われる。
この方法では、学習中に、ニューロンの出力をランダムにゼロにする。
これにより、ネットワークの平均化が期待できる。
これにより、アンサンブル学習が実現できる。
このようにネットワークを調節しているのです。
この講義では、このアルゴリズムの仕組みは説明しない。
このビデオのテーマは、生成的敵対モデル（generative adversarial model）です。
生成モデルとは何かについて考えてみましょう。
講義を通して見てきたネットワークは分類のために使われます。
これらのモデルは、入力データのクラスを決定します。
上の例から、「0」を入力とし、その出力「0.9」と「0.2」を取る。
そして、出力を1光子ベクトルに変換することで、入力を 0 に分類するモデルです。
下の例も同様に出力を「1」に分類しています。
これがMLP、CNN、RNNの仕組みである。
一方、生成モデルでは、フィードフォワードネットワークに入力として与えるデータを作成する。
例えば、0.9や0.2といった「0」の特徴量を入力すると、「0」のような画像が生成される。
一方、0.1や0.8といった特徴量を入力すると、1らしい画像が生成される。
生成モデルにはいくつかあり、例えば
ボルツマン・マシン、変分オートエンコーダ、GAN（Generative Adversarial Network）である。
ボルツマン・マシンは古くから研究されているネットワークである。
以下、この2つのモデルは最近発明されたものです。
GANは多くの分野で応用されているので、見たことがある方も多いのではないでしょうか。
GANの詳細は後述します。
Generative Adversarial Network (GAN)。
このモデルは多くの分野で応用され、近年注目されています。
これも生成モデルであり、教師なし学習で学習することができる。
画像クラスの確率を出力する識別器。
と、特徴量からデータを出力する生成モデル、この2つがGANで使われている。
ニューラルネットワークが他のニューラルネットワークを評価する。
識別器には、本物か偽物かの情報のみがスーパーバイザ信号として与えられる。
生成モデルは識別器によって繰り返し学習される。
生成モデルと識別器の間を行き来するための明示的な教師は必要ない。
この図にGANの概要を示す。この構造自体が大きな発明であった。
GANは生成モデルであるGenerator「G」と分類器であるDiscriminator「D」を持っている。
G」と「D」をいかにうまく学習させるかがポイントになる。
大まかな構造を見てみよう。
画像のようなデータ「Y」は、生成器が乱数を用いて生成する。
実データ「X」と偽データ「Y」を使って識別器を実行する。
D の入力が本物か偽物かの情報は、識別器によって与えられる。
「D と G は、本物か偽物かの監視データを用いて、バックプロパゲーションで学習される。
これには2つのニューラルネットワークと2つのデータが必要である。
ネットワークが生成した偽データと実データの2つのデータが必要である。
と監視データである。
識別器と生成モデルは互いに重要な役割を担っている。
識別器の役割は、監視データと生成データを区別することである。
識別器は監視データに対して Real と答える必要がある。
また、別のネットワークで生成されたデータに対しては「Fake」と答える必要がある。
生成モデルの役割は、監視データと類似したデータを生成することである
というような、識別器では識別できないデータを生成することである。
したがって、これらのモデルは互いに補完し合う必要があるため、このネットワークは敵対的ネットワークと名づけられた。
分類器はデータを正しく識別したい。
生成器は生成されたデータで判別器を欺きたい。
それぞれの目的は敵対的である。
これを学習することで、生成モデルが生成するデータはより実際の監視データに近くなる。
識別器の学習段階において、真の情報は D に与えられる。
は、生成器の学習段階において、偽の情報を D に与えている。
識別器の学習方法について見てみよう。これは2種類のデータを持つ。
実データ X は、D に 実 と答えさせるために、監視データ 実 と一緒に与える。
生成データ Y は、fake という監視データとともに与えられる。
生成画像 Y は Z のシードを与えて乱数を発生させることで生成される。
以下のパスでは、Z を入力し、G で Y を生成し、Y を D に渡している。
D は Y と監視情報 Fake を用いて学習される。
この段階では、G の値は更新されない。
一方、識別器の学習フェーズでは
「Y を乱数で生成し、識別器に渡す。
G は、生成されたデータが本物であることを判別器に 分類して欲しいと考えている。
Gは偽物とわからないようなデータを生成したいので。
偽の監視情報「real」を「D」に渡し、バックプロパゲーションを行う
このフェーズでは、生成器の値のみを更新し、識別器は更新しない。
識別器と生成器は繰り返し学習される。
識別器の学習では、実画像を識別できるようにDを学習する。
生成器の学習フェーズでは、「G」を学習させ、「G」が生成する画像は...。
を生成するように学習させる。
これを繰り返すことで、「D」も「G」も強くなり、出力される「Y」は人間の目にとってリアルなものになる。
各部の処理はそれほど難しくなく、多くの拡張が可能です。
例えば、乱数発生器をエンコーダーに置き換えることも可能である。
また、画像以外のデータも生成可能である。
D と G は、画像処理にCNNを、時系列データにはRNNを用いることができる。
GANには様々な応用がある。
例えば、深層畳み込みGANは、概念の足し算、引き算を計算することができる。
眼鏡をかけた男性マイナス眼鏡をかけない男性プラス女性は、眼鏡をかけた女性というように。
もう一つの例は、スタイル変換である。
例えば、GANは馬とシマウマの関係を学習し、馬の画像からシマウマを生成する。
また、最近悪用されている例としては、芸能人の偽の動画を作成し、SNSで拡散させるというものがある。
GANの応用分野は多岐に渡り、大きな可能性を秘めている。
例えば、画像の精度向上、線画の色付け、テキストからの画像生成などである。
しかし、ネットワークの学習が困難な場合もある。
これらの問題を解決するための研究テーマはたくさんあります。
ぜひ、GANの演習に取り組んでください。
それでは、AIセミナーの講義を始めます。
今日のテーマはリザーバーコンピューティングです。
リザーバーコンピューティングの概念を見てみましょう。
下の画像をご覧ください。
水を貯めるための容器や湖を想像してください。
その中に石を投げ入れるとします。
このとき、3つの石を連続して投げ入れると
3つの石が作る水面の波紋を観察することができます。
石の大きさや形によって波紋は変化します。
また、投げる順番によっても波紋は変化します。
石によって水面がどのように変化するか、想像できるでしょうか？
貯水池コンピューティングは、あるアイデアをきっかけに生まれました。
波紋の形状を観察することで、時系列データの特徴を抽出することができます。
石を投げた順番や時間が、湖面の波紋として現れる。
つまり、記憶が表現されているのです。
時系列処理に適している。
貯水池に簡単な識別器をつけることで
パターンを解析することができる。
読み出しは、リザーバーに取り付けたリーニングマシーンである。
複雑なパターンを表現するリザーバーと、シンプルなリーニングマシンにより
時系列データをリーン化することができる。
読み出しには線形学習機がよく使われる。
線形関数の係数は学習により決定される。
本講座では冒頭でパーセプトロンを学習した。
時系列データも簡単な学習機で学習できる。
これがリザーバーコンピューティングの利点である。
ここで、線形学習機、ディープラーニング、リザーバーコンピューティングを比較してみよう。
線形学習機1台では、非線形の入出力関係を学習することはできない。
ディープラーニングは、学習コストは高いが、計算性能は高い。
その計算性能は高い。
非線形の入出力関係を学習することができる。
リザーバーコンピューティングは、線形リーニングマシンとリザーバーの組み合わせである。
低い学習コストで非線形の入出力関係を学習することができる。
しかし、計算性能はタスクによって異なる。
下図は教科書から引用したものである。
この図は、性能と学習コストの関係を示している。
リザーバーコンピューティングの学習コストは、線形学習機とほぼ同じである。
であり、性能は高い。
同規模のディープラーニングモデルと比較すると、調整すべきパラメータ数が少ない。
学習コストが低いとはいえ
計算性能にばらつきがある。
リザーバーを利用することで
軽量なリカレントニューラルネットワークを構築することができる。
リザーバーコンピューティングは、ディープニューラルネットワークと比較して、高いポテンシャルを有しています。
最近注目されている計算モデルです。
ここでは、リザーバーコンピューティングの代表的なモデルであるESN（Echo State Network）を見ていこう。
ESNは時系列パターン認識などに利用されている。
入力履歴がエコーして残るエコー状態がリザーバーに作られる。
リザーバーに現れた特徴は、学習された読み出しによって処理される。
学習されるのは読み出しのみである。
単純な学習機械が読み出しに使われることが多い。
リザーバーでは、リカレントニューロンが複雑に接続されている。
この接続は固定されており、学習されない。
W^outのみが学習されるため、学習コストは低い。
これは下図のベクトルの定義である。
入力はN_u次元のベクトルである。
リザーバには x_1 から x_N_x までの多数のニューロンがある。
これが読み出しに接続される。
出力層の次元は N_y である。
W_in は入力層とリザーバを接続する接続重みである。
リザーバ内の接続重みはWである。
W^out はリザーバと出力層を接続する接続重みである。
W_in と W は固定で、W^out だけを学習する。
リザーバ内の時系列パターンの表現を見てみよう。
入力ベクトルと W^in は乗算され、リザーバに与えられる。
リザーバ内では、ニューロンはリカレント接続される。
追加される前の1回分のステップでのリカレント接続。
リザーバの状態ベクトルの時間発展を表現することができる。
各ニューロンには、非線形活性化関数が適用される。
活性化関数は特に断らない限り双曲線タンジェントである。
出力ベクトルは、リザーバの状態ベクトルと W^out の掛け算である。
ESNの派生モデルを見てみよう。
これが今まで見てきた基本モデルです。
これらは、ESNの派生モデルの例である。
この講義では、(a)の一般的なモデルについて説明します。
基本モデルと一般モデルには、いくつかの違いがあります。
まず、出力層とリザーバをつなぐフィードバック接続があること。
次に、入力層と出力層のディレクトリをつなぐ接続がある。
接続を追加しても、W^outだけが学習される。
緑で示されるフィードバック接続の重みは固定である。
ニューロンにはいくつかの種類があります。
ここでは、Leaky Integrator(LI)モデルについて説明する。
LIモデルを用いることで
LIモデルを用いることで、リザーバの状態ベクトルの時間発展の速度を制御することができる。
したがって、過去の情報をどの程度保存するかを制御することができる。
Î±はリーク率であり、このモデルのハイパーパラメータである。
Î±=1のとき、右項のみの効果である。
これは基本モデルに相当する。
Î±が小さくなると、リザーバの状態の変化は入力であるuに影響を与えない。
リザーバーの時間発展はより遅くなる。
この効果は、時系列入力データの高周波成分を除去するローパスフィルタのようなものである。
このモデルを用いることで、性能の向上が期待できる場合もある。
これがリザーバーコンピューティングのシンプルで効果的な微分モデルである。
次に、ESNの重要な考え方であるESP(Echo State Property)について説明する。
ESPとは、時系列入出力変換器としての再現性を保証する性質である。
これは、リザーバーが満たすべき性質の一つである。
リザーバの状態ベクトルは、初期状態と時系列入力によって決定される。
初期状態が変化すると、同じ入力を与えてもリザーバの応答が異なる場合がある。
このような初期状態の影響を防ぐために
初期状態の影響を防ぐためには、十分な時間が経過した後に、時系列入力のみによってリザーバの状態の時間発展を決定する必要がある。
これが前文の数学的表現である。
異なる状態から出発したリザーバー状態ベクトルは、例えばゼロに変換された値など、同じ値に変換される。
この図に示すように、異なる状態から始まるリザーバーの状態ベクトルは、同じ軌道に変換されることになります。
リザーバーはこの性質を満たす必要がある。
これがESPを満たす条件である。
ここで、活性化関数は双曲線タンジェントである。
指標としてスペクトル半径を用いることが多い。
スペクトル半径とは、リザーバの接続重みの最大固有値のことである。
すべての固有値は1以下であることが望ましい。
すべての固有値が1より小さい行列に掛け続けると、ベクトルは短くなる。
はベクトルが短くなる。
この操作を繰り返すことで、ベクトルは0に変換されます。
これがESPを満たす有名な条件です。
貯水池を設計する際には、この条件を考慮する必要があります。
もう一つの条件は、最大特異値である。
ここでは詳細を見ないが、この条件は必須ではないのかもしれない。
基本的にリザーバを設計する際には、スペクトル半径を考慮する。
学習方法について説明する。
学習は読み出しのみである。
他の教師あり学習と同様に、入力と目標信号を与える。
回帰問題を解く場合は、連続的な目標値が与えられる。
分類問題を解く場合は、1ホットのベクトルが与えられる。
読み出しの学習には、いくつかの方法があります。
これは典型的な読み出しの学習方法です。
これは線形回帰の例である。
ここでは、ターゲットとモデルの出力の2乗誤差を最小にするW^outを求めます。
DとXの2乗誤差を最小にすることにする。
この式は次のような式に変形することができる。
これが基本的な方法である。
次に、リッジ回帰を見てみよう。
この方法では、式に正則化項を追加する。
W^outが大きくなるのを防ぐことができる。
これが変形された式です。
この講座で見てきた正則化と似ていますね。
この式を解くことでW^outを決定することができます。
学習コストは低くなります。
最後に、タスクの例を見てみましょう。
これは線形回帰の例である。
このタスクでは、次の時間ステップでの正弦波の値を予測する。
リザーバーに入力時系列データを与え、読み出しのトレーニングを行います。
リッジ回帰を用いることで、正弦波を予測することができる。
出力は連続した値である。
次に、分類の例を見てみましょう。
これは音声認識の例である。
出力値が0の場合、「0」の出力ニューロンだけが1になります。
他のニューロンは反応しません。
ターゲット信号は、クラスに対応するワンホットベクトルである。
このリザーバーコンピューティングは、音声認識にも応用できる。
しかし、原信号の学習が困難であるため、入力音声の前処理が必要である。
そこで、音声信号を周波数帯に応じて分解する。
前処理を導入することで、リザーバコンピューティングにより音声信号の分類が可能となる。
さて、今日のトピックを簡単におさらいしておきましょう。
リザーバーコンピューティングは軽量なモデルで、ディープリカレントニューラルネットワークに匹敵する能力を持っている。
最近注目されています。
これで今日の講義は終わりです、ありがとうございました。
オートエンコーダの種類をいくつか見ていきます。
今日はオートエンコーダ（AE）を見ていきます。
多層パーセプトロン（MLP）、CNN、RNNの学習には、監視信号が必要です。
一方、オートエンコーダーは、学習時に監視信号が不要です。
このネットワークは、図のような砂時計のような形をしている。
(90度回転させると砂時計のような形をしているのがわかると思います)。
隠れ層は、入力層や出力層よりも少ないユニットで構成されています。
形が砂時計に似ていることから、砂時計と呼ばれている。
オートエンコーダーは教師なしモデルである。
入力を出力にコピーしようとするように学習される。
明示的な監視信号を持っていない。
言い換えれば、入力そのものが教師である。
入力層から隠れ層までの部分をエンコーダと呼ぶ。
隠れ層から出力層までの部分をデコーダと呼ぶ。
オートエンコーダの構成で重要なポイントは
であり、隠れ層の数を入力層の数より少なくすることである。
MLPと同様にパラメータとして重み「w」とバイアス「b」を持つ．
重みの値を共有するTied Weightは，オートエンコーダの構成方法の一つです．
入力層から隠れ層への重みと，隠れ層から出力層への重みの値を同じにすることで，学習パラメータの数を減らすことができます．
を同じにすることで、学習パラメータの数を減らすことができる。
また、正則化としても影響する。
同系列の重みは、学習性能の向上に役立つ。
このネットワークは、入力と同じ値を出力するだけで、特徴を抽出することができる。
入力をユニットの少ない隠れ層にマッピングし（エンコード）、隠れ層を出力にマッピングすることで
と、隠れ層をユニットの多い出力層に対応させる（デコード）ことで
入力よりも少ないユニット数で元の情報を表現することができる。
原画を表現するのに有効な特徴は、中間層で表現される。
そのため、特徴を抽出し、次元を減らすことができる。
例えば、10×10ピクセルの画像で100次元の画像があるとする。
このとき、次元を10に減らすことができれば、データを圧縮することができる。
エンコーダの機能を自動的に学習することから、オートエンコーダと呼ばれるようになった。
主成分分析（PCA）は、線形データ圧縮法である。
AEは、PCAを非線形分布に拡張したモデルである。
手書き数字の成分は、MNISTデータセットから学習することができる。
PCAとオートエンコーダの違いを見てみよう。
x で示されるデータは、PCAでは直線に近似することができるが
オートエンコーダでは、データ x にフィットする非線形直線に近似されます。
次に、積層型オートエンコーダ(SAE)について説明します。
ここでは、オートエンコーダの積み重ねについて説明します。
前のスライドで見たオートエンコーダは、隠れ層が1つしかない。
MLPのようにオートエンコーダの層を追加することで、MLPと同じ利点を得ることができます。
精度を上げることができ、少ないユニットでデータを表現することができます。
私たちはSAEの学習方法をいくつか持っています．
そのうちの1つがgreedyアルゴリズムであり，通常はうまく機能します．
これは隠れ層が2つのSAEである。
このネットワークは、入力と同じ出力を与えることで一度に学習することが可能です。
しかし、層ごとに学習させた方がうまくいくことが分かっています。
まず、一番大きい部分を学習させる。
次に、学習させた隠れ層を取り出し、赤色で示したデコーダを削除する。
最初に学習したネットワークの隠れ層、中間特徴量である「y」を入力とする。
次のステップでは、より小さなオートエンコーダを学習させ、特徴量 y^を返すようにする。
このとき、新しい素性「z」を得ることができるのは、オートエンコーダの役割である。
同じ操作で緑色の部分を取り除くと、x、y、zのネットワークが得られる。
x は y に圧縮され、y は z に圧縮されています。
デコーダーの部品も同じ処理方法で積み重ねます。これでようやく、大きなネットワークが構築できる。
ポイントは、このような大きなネットワークから、層ごとに処理をして小さなネットワークを作ることであり、この方法は事前学習に使われている。
2006年には、ディープニューラルネットワークのトレーニングに成功したという最初の報告がなされた。
それ以前は、ディープニューラルネットワークの学習は困難と言われていました。
それ以前は、学習の発散や勾配の消失といった問題があるため、ディープニューラルネットワークの学習は難しいと言われていました。
しかし、オートエンコーダーを用いた事前学習により、ディープニューラルネットワークを学習できることが証明されました。
黄色い部分は、スタック型オートエンコーダを用いてあらかじめ特徴を抽出しておき、最後のステップで、その特徴を用いてニューラルネットワークを学習させる。
そして、最後のステップでは、小さなMLPに対して微調整を行うことで、ネットワークを学習させることができます。
この方法はディープリーンの発展に貢献した。
これはディープラーニングの発展に貢献した最初の技術です。
以前は、ディープニューラルネットワークの初期重みを得るために、スタックドオートエンコーダが利用されていました。
次に、改良型オートエンコーダを見てみましょう。
まず、SPAE（Sparse-AutoEncoder）を見てみましょう。
SpAEでは、あらかじめ多くのユニットが隠れ層に配置されています。
この例では、隠れユニットが入力ユニットより多くなっています。
しかし、データ量は入力より多く、データを圧縮することはない。
そこで、データ圧縮が可能なように、疎なユニットを作る。
隠れ層は、入力が来たときにニューロンの出力が0になるように学習させる。
0の値を持つユニットの数を調整することで
のユニット数を調整することで、隠れ層の活性ニューロンの数を減らし、データ圧縮を可能にしています。
つまり、自由度が高く、学習による効果的なネットワーク構造を選択することができる。
これは、新たな正則化項を追加することで実現される。
仮にEをオリジナルの損失関数とする。
第二項に単位をスパースにする正則化項を追加することで
Kullback-Leibler divergence (KLD)を用いて計算を行う。
ρ_jハットは、ユニットの反応を示す出力 y の累積値である。
ハイパーパラメータであるρの値を小さくすると、0 のユニットの数が増加する。
また、ρの値を大きくすると、0の個数が減少する。
このρを適切に設定することで、適切な数のユニットが活性化され、良好な特徴量を得ることができる。
βは、ユニットをどれだけ活性化させるかを決める寄与率である。
例えば、βを0.1に設定すると、そのままの数値が出力される。しかし、これでは良い特徴とは言えない場合がある。
βの値を再調整することで、得られた特徴を調整することができる。
次に、Denoising AutoEncoder (DAE)を見てみましょう。
オートエンコーダは、入力と同じ値を出力するように学習させます。
入力データには、状況に応じてノイズが含まれることがあります。
この例では、入力 4 に意図的にガウスノイズを加えています。
出力が 9 のように見えるため、世代交代は失敗した。
解決策としては、シンプルで強力なアルゴリズムが必要である。
入力データにのみ様々なノイズを付加し、出力はオリジナルデータを与える。
ノイズに強い特徴量を得ることができる。
データを強制的に緑の線に乗せる可能性が高くなる。
DAEの考え方は、様々な応用が可能です。
次に、変分オートエンコーダ（VAE）を見てみましょう。
オートエンコーダは、隠れ層として特徴量を持つ。
出力層は入力を再構成するように動作する。
内部値は決定論的である。
一方、VAEでは隠れ層のユニットが確率的な値を表す。
これにより、出力層は入力を表す確率を生成することができる。
内部値も確率的に動作する。
例えば、内部値が「0.5」であれば、50%の確率で「1」を出力する。
ポイントは、内部値が確率であって、通常のオートエンコーダのように明確な値ではないということだ。
それでも、構造は似ている。
隠れ層は乱数を表現する。
これは乱数の平均値と分散を表しています。
この図は説明のために90度回転している。
乱数は、乱数発生器に種を入力することで得られる。
得られる値はシードで異なるが、同じシードからは同じ乱数が得られる。
入力はシードとして使用される。
上の2つの画像は、どちらも「0」の形をしている。
0 っぽい画像が 0 の種を作る。「4 のような画像は 4 の種を作る。
隠れ層の値は、乱数発生器と同じように、シードによって作られる。
このことから、このモデルの処理として、乱数生成処理を比較することができる。
出力層は、入力を表す確率を与える。
このモデルは乱数によって動作しているため、同じ入力に対して異なる出力を与えることができる。
出力層を可視化すると、ぼやけた出力が得られる。
簡単におさらいしておこう。
入力の流れは下から上に向かっています。
まず、入力層から種を生成する。
似たような画像から似たような値を生成する。
得られたシードから隠れ層用の乱数を生成する。
最後に、隠れ層から出力層に変換される。
その値は確率として表される。
以上でオートエンコーダの講義パートは終了です。
演習パートにお進みください。
皆さんこんにちは、AIゼミの講義を始めます。
今日のトピックはRecurrent Neural Networks (RNNs)です。
以上が今日の講義のトピックです。
まず、時系列データについて説明します。
次にRNNの説明をします。
では、時系列データについて説明します。
時系列データとは、時間の経過とともに変化するデータのことです。
これは時系列データの例です。
今、私が話している自然言語が時系列データです。
文章や会話も自然言語に含まれる。
他にも、株価や天気など、日々変化するデータも時系列データです。
一般に、ある時刻の値は、過去の時刻の値や未来の値と相関があることが知られている。
例えば、自然言語には文法がある。
日本語の場合、動詞や名詞は一定の規則に従って出現する。
従って、この時系列データは、過去データ未来データに関連するデータであると考えられる。
簡単な例として、気温のデータを見てみよう。
このグラフは、横軸に日付、縦軸に気温をとっています。
横軸は左から右へ時間が経過していきます。
このグラフは、温度が徐々に上がっていく関係を示しています。
このデータを使って何ができるかを考えてみましょう。
例えば、温度を予測することができます。
気温が予測できれば、天気予報に役立てることができる。
しかし、時系列データを処理するのは非常に難しい。
時系列データは、過去のデータと未来のデータに相関があることが多い。
そのため、直前に蓄積されたデータも考慮する必要がある。
例えば、1月4日の気温を予測するには、直前のデータを考慮する必要がある。
1月4日の気温を予測するためには、1月1日から1月3日までのデータを考慮する必要があります。
前回の講義で学んだMLPで、どのようにデータを予測するかを考えてみましょう。
この場合、参照する過去のデータの数によってMLPの構造が変化します。
この時系列データでは、1月3日だけを見て1月4日の気温を予測することは困難です。
先ほども申し上げたように、長い期間のデータを使った予測の方が精度が高いのです。
また、翌日の気温を予測するために、どれだけの過去のデータが必要なのか判断が難しいところです。
しかし、MLPの場合、参照範囲を決めないと構造を作ることができません。
例えば、過去の気温を3日分参照したい場合、入力層の数は3つです。
過去4日間の気温を参照するのであれば、入力層の数は4層になる。
このように、参照する量をあらかじめ決めておかないと、ネットワークの構造を定義することはできない。
また、何日分を参照すべきかを知ることも困難である。
そこで登場するのが、RNN（Recurrent Neural Networks）である。
まず、その構造を見てみよう。
Recurrent Neural Networksは、略してRNNと呼ばれます。
このニューラルネットワークは、隠れ層にフィードバック構造を持っています。
この方式は、ニューラルネットワークに時間の概念を導入しています。
MLPの場合、入力は隠れ層（複数可）で処理され、出力（複数可）を得ることができます。
RNNは、隠れ層にフィードバック構造を持つ。
フィードバックの接続も、訓練によって獲得される。
RNNの特徴の一つは、h^t が現在の入力と1回前の隠れ層の状態によって決定されることである。
まず、簡単に理解してみよう。
RNNは、隠れ層にフィードバック接続がある。
本講義では、今後、このブロック図を使用することにします。
ニューロンやシナプスを使った表記ではなく、このブロック図を使います。
右図の四角と矢印は、左図と同じ意味であることを忘れないでください。
このうち、黒い矢印だけが右を向いている図を、RNN（Forward Propagation Network）と呼びます。
RNNの重要な特徴は、自分自身へのフィードバック接続を持っていることです。
ここでも、今後は右の表記を使うことにする。
まず、RNNの順方向の計算を考えてみましょう。
隠れ層の出力「h^t」の計算方法は、MLPのそれとは異なります。
MLPの場合、隠れ層の出力は、入力に重みを掛けて活性化関数を適用することで得られます。
RNNの場合は、フィードバック接続があるため。
隠れ層の出力は、...によって得られる。
フィードバック接続と、1回前のステップの隠れ層の状態を掛け合わせる。
を、入力と出力の掛け算に加えて行う。
比較的理解しやすいと思います。
左からの入力をフィードバック接続の部分と一緒に考えるということです。
さて、前方伝搬の計算です。
ネットワークをどのように学習させるか考えてみましょう。
ネットワークの学習は，MLPのようにバックプロパゲーションによって，重みとバイアスの勾配を計算することで行います．
重みとバイアスは最適化することで更新されます。
下の図を見てみよう。
順伝播における出力は、目標と比較され、その誤差がフィードバックされます。
この黒い矢印はMLPと同じです。
RNNの場合は、このフィードバック接続も勾配を利用して更新されます。
ポイントは、黄色の部分をどう計算するかです。
隠れ層を時間方向に展開していきます。
ネットワークを時間方向に展開する方法を考えてみましょう。
隠れ層の入力は、前の時間の隠れ層の出力と、現在の時間の入力です。
黄色の部分をどのように計算するかを考えてみよう。
黄色の部分を時間軸で展開すると、右図のようにネットワークが表現されます。
t, t = 1, t = 2, t = T は時間である。
一番左の「t＝1」を考えてみましょう。
時刻1の入力「x^1」は隠れ層を通過し、出力「y^1」が得られます。
次に、「t = 2」を考えてみましょう。
現在の入力 x^2 と出力 y^2 を組み合わせて、出力 y^2 を得る。
と1回前のステップの隠れ層 h^1 の状態から得られる。
h^1」から「h^2」への矢印は、左図の「h^(t - 1)」に相当する。
t = 3」、「t = 4」についても同様である。
回数を増やすと、横方向に拡大される。
左の図では、フィードバック接続で表現されています。
この黄色い部分はすべて隠れ層です。
隠れ層が「T」個ある巨大なMLPと考えられます。
巨大なMLPですから、バックプロパゲーション方式を使うことができます。
この考え方は、時間による逆伝播という考え方です。
略してBPTTといいます。
BPTTは巨大なMLPなので、各グラフから誤差を伝播させることで、この隠れ層の重みを学習させることができます。
これは非常にシンプルな考え方です。
BPPTは時系列データの扱い方によって、大きく2つのパターンに分けられます。
1つ目：対象データを全時間ステップに提供する場合。
これは、毎回データを予測するときに使う。
誤差を計算し、全時間帯で合計してバックプロパゲートする。
2つ目：対象データが最終回のみ提供される場合。
これは、ある時間間隔で分類問題を解くときに使われる。
誤差は最終時刻に計算され、バックプロパゲートされる。
最初のパターンであるBPTT1を見てみましょう。
すべての時間ステップで対象データがあります。
この例では、3回の時間ステップを考えてみよう。
x^1 が入力されると、y^1 が出力される。
すると、「y^1」に対して「y^1_(target)」となり、誤差「E^1」が得られます。
同様に、x^2 に対して y^2 が得られ、誤差 E^2 が求まる。
E^3 も同様に求めることができる。
得られた3つの誤差を合計することで、バックプロパゲーションを計算することができる。
典型的な例として、翌日の気温を予測する問題がある。
この例では、過去数日間の気温をもとに翌日の気温を予測する。
3日分のデータを使って翌日のデータを予測したい場合、それらのデータをターゲットとして与える。
誤差はすべてのデータについて累積することができる。
このネットワークでは、1月1日の気温から翌日の気温「y^1」を2.8度予測する。
翌日の実データが得られるので、それをターゲットとする。
そして、「y^1」からの誤差をフィードバックして、「h^1」を学習させる。
次に、1月3日の気温を予測する。
このとき、ネットワークは1月1日と2日のデータを使って気温を予測する。
y^2 は、この現在のステップと前のステップの値の2つを合成することで得ることができる。
1月3日のデータをターゲットとして、y^2 から誤差を求める。
h^1」「h^2」ともに、得られた誤差「E^2」をバックプロパゲートすることで更新される。
ポイントは「h^2」で分岐があること。
ネットワークを何度も展開すると、この図のようになる。
例えば、この部分は「E^1」「E^2」「E^3」の誤差を全て合計することで更新される。
この例では、3つのタイムステップのデータを使っている。
この操作をルール化することで、多くの時間ステップのネットワークを計算するプログラムを作ることができる。
次のパターン、BPTT2を見てみよう。
この場合、ターゲットは最後の時間であるステップ3について与えられる。
この場合、誤差「E^3」だけが分岐してバックプロパゲートされる。
典型的な例としては、分類がある。例えば、気温のグラフをもとに季節を分類する。
例えば、7タイムステップのデータが与えられると、「冬」というラベルが出力される。
BPTT2の考え方は、BPTT1とほぼ同じです。
違いは、すべてのデータが入力されたときの誤差を計算することである。
フォワードプロパゲーションの場合は、この図のようにマージされます。
バックプロパゲーションの場合は、この図のようにマージされます。
このように、巨大なRNNを巨大なMLPとみなして、バックプロパゲーションを用いて学習させることができます。
しかし、RNN、特にBPTTで学習させたRNNには欠点があります。
BPTTは、巨大なMLPと考えることができます。
T=100のネットワークは、100層のMPLに相当します。
「y^T は、隠れ層へのデータの通過を100回行うことで得られます。
順伝播の場合、長期の時系列データを蓄積することはできない。
バックプロパゲーションで学習する場合、勾配消失問題や勾配爆発問題が発生する。
これらの問題は、ニューラルネットワークの問題として古くから知られている。
このため、学習がうまくいかない。
この問題を克服するために、いくつかのネットワークが設計されている。
代表的なものはLSTM(Long Short-Term Memory)である。
LSTMはBPTTの欠点を克服している。
このネットワークは長期記憶を獲得することができます。
これは、長い文章を扱うときによく使われます。
LSTMでは、隠れ層の出力が十分に活用されているかどうかを内部で判断しています。
LSTMの基本的な考え方だけ説明します。
入力ゲートは、ネットワークへの入力量を調整する。
メモリーセルは、以前の状態を記憶する。
忘却ゲートは、状態の忘却度を調整する。
出力ゲートは、次の層への出力量を調整する。
このように、LSTMは複数のゲートでネットワークの入出力と状態を制御している。
LSTMについてもっと詳しく知りたい方は、教科書やインターネットで公開されている記事などを参考にしてください。
今日は、リカレントニューラルネットワークについて見てきました。
時系列データの扱い方とBPTTについて。
最後に、実用的なRNNの1つであるLSTMの基本的な考え方について見てきました。
これで本日の講義は終了です。
今日は、畳み込みニューラルネットワーク（CNN）について勉強します。
CNNは、画像認識のために設計された強力なニューラルネットワークです。
現在のAIブームの火付け役となりました。
2012年の画像認識コンテストで、このCNNは性能に大きな差をつけて1位を獲得しました。
AIのブレークスルーとなり、その後もさまざまなCNNのモデルが開発されている。
CNNは画像処理の基本モデルであり
CNNは、物体認識、姿勢推定、物体検出、セグメンテーションなど、画像処理の基本モデルである。
また、CNNは様々な分野で応用されている。
また、自然言語処理、音声信号処理、時系列予測など、様々な分野で応用されている。
CNNは畳み込み処理とアフィン変換から構成されている。
有名なCNNはLeNetモデルである。
は、畳み込み処理として畳み込みとプーリングを2回行う。
LeNetはアフィン変換のために3つの完全連結層を持っている。
畳み込み処理では、画像の特徴を抽出する。
したがって、このネットワークは、基本的なニューラルネットワークに特徴抽出を追加したものである。
しかし，完全連結型ネットワークである多層パーセプトロン（MLP）は，分類問題を扱うことができます．
これは、特定のパターンに特化したものです。
スライドにある7という数字は、人間にとってはどちらも同じに見えますが、この2つの7はそれぞれ微妙に異なっています。
しかし、この2つの7は微妙に異なっています。
白いピクセルが下にずれているのです。
MLPでは、このようなシフトした特徴を扱うことができません。
例えば、このネットワークを学習させ、白いピクセルが中央に来たとき、ニューロンが強く発火したとします。
もし，1ピクセルだけシフトしていたらどうなるでしょうか？
このネットワークはシフトされた入力に対して学習していない。
最終層は発火しない
というのも，強く接続された部分と白いピクセルの位置が一致しないからです．
そのため，MLPでは，人間の目の中でわずかな違いがあっても，その特徴を抽出することができません．
しかし、CNNはこの問題を克服しています。
それは，局所的なパターンに特化したものです．
MLPでは、入力層と隠れ層にあるすべてのニューロンが接続されていました。
単純な接続パターンを繰り返し配置することで
隣接するニューロンと接続されます．
その結果，局所的なパターンを広範囲に抽出することができるのです．
また、平行移動に対して不変なニューラルネットワークを構築することが可能である。
CNNは、畳み込みとプーリングの組み合わせで特徴を抽出する。
小さなフィルタからエッジ情報を抽出することができる。
画像認識に有用である。
複雑なセルは単純なセルの組み合わせで構成される。
また、プーリングにより、動きに対して不変な特徴量を抽出する。
このように、認識に必要な特徴を効率的に抽出することができる。
それでは、畳み込みとプーリングについて、もう少し詳しく見ていこう。
畳み込みは、画像フィルタに似ている。
例えば、スライドに示すような入力パターンとフィルターパターンがあるとする。
この式に示すようにコンボリューションを実行します。
行列の左上の領域にフィルタを適用した結果は24です。
画像の画素とフィルタの乗算積算を実行します。
水平方向のエッジと垂直方向のエッジを抽出する画像フィルタを作ることができる。
CNNの学習により、画像フィルタはより効果的に画像を認識するようになる。
次の処理は、プーリングである。
これには2つの目的がある。
1つは、データの次元を減らすことである。
フィルタを適用して特徴量を抽出すると、特徴量の次元数が減少する。
特徴量の次元数が増えていきます。
ポイントは、重要な情報を残すために次元を減らすことである。
もうひとつは、翻訳不変性の獲得である。
プーリングは大きく分けて2種類ある。
この例では、4×4画像を2×2画像に変換している。
max-poolingは、ブロック内で最も大きな値を返す処理である。
平均値プーリングは、ブロックの平均値を出力する処理である。
ここで、なぜプーリングが移動不変性を獲得できるかを考えてみよう。
この例では、4画素に対してmax-poolingが実行されている。
右側の画素では、文字認識に有用と思われる白い画素を1画素分下方にずらしている。
どちらの場合も、max-poolingの結果は同じである。
を抽出することができる。
動き不変の特徴を獲得できる。
ここまで、CNNの基本である畳み込みとプーリングについて見てきた。
エッジ上の画素にはフィルタが適用されない場合がある．
境界付近の画素はパディングで処理することができる．
パディングを0にすることをゼロパディングという．
パディング、スライドをネットワークパラメータとして設定することができる。
パディングを行うことで、入力と同じ大きさの出力を得ることができる。
ここで、なぜプーリングが移動不変性を獲得できるかを考えてみよう。
この例では、4画素に対してmax-poolingが実行されている。ストライドとは、フィルタのシフト量である。
Stride 1は最小値。つまり、フィルタを1画素分ずらしたことになる。
右側の画素では、文字認識に有用と思われる白い画素が1画素分下方にずれている。
ストライド2は、フィルタを2ピクセル分ずらすことを意味します。
ストライドはパラメータとして設定することもできる。
得られる特徴マップの大きさは、パディングの数とストライドに依存する。
小さなフィルタによって局所的な特徴を抽出することができる．
CNNには多くのモデルがあり、有名なCNNはユニークな名前を持っている。
LeNet は古いニューラルネットワークである
2つの畳み込み層(Conv.)と3つの完全連結層(FC)で構成されている。
AlexNetは2012年のコンペティションで優勝した有名なCNNネットワークです。
他にもVGG、GoogLeNet、ResNetなど有名なネットワークがたくさんあります。
この他にも、VGGやGoogLeNet、ResNetなど、有名なネットワークがたくさんあります。
毎月のように発表されています。
演習パートでは、CNNを使った文字認識の課題に取り組んでください。